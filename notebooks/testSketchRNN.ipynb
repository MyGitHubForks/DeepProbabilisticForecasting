{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append(\"../batchedRNN\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../batchedRNN/model/SketchRNN.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SketchRNNEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SketchRNNEncoder, self).__init__()\n",
    "        if args.bidirectionalEncoder:\n",
    "            self.directions = 2\n",
    "        else:\n",
    "            self.directions = 1\n",
    "        # bidirectional lstm:\n",
    "        self.lstm = nn.LSTM(args.x_dim * args.channels, args.encoder_h_dim, \\\n",
    "            args.n_layers, dropout=args.encoder_layer_dropout, bidirectional=args.bidirectionalEncoder)\n",
    "        # create mu and sigma from lstm's last output:\n",
    "        self.fc_mu = nn.Linear(args.n_layers * self.directions * args.encoder_h_dim, args.z_dim)\n",
    "        self.fc_sigma = nn.Linear(args.n_layers * self.directions * args.encoder_h_dim, args.z_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            hidden_cell = self.init_hidden_cell()\n",
    "        _, (hidden, cell) = self.lstm(input, hidden_cell)\n",
    "        # convert hidden size from (n_layers * directions, batch_size, h_dim)\n",
    "        #                       to (batch_size, n_layers * directions * h_dim)\n",
    "        hiddenLayers = torch.split(hidden, 1, 0)\n",
    "        if self.directions == 2 and args.n_layers == 2:\n",
    "            assert len(hiddenLayers) == 4\n",
    "        hidden_cat = torch.cat([h.squeeze(0) for h in hiddenLayers], 1)\n",
    "        mu = self.fc_mu(hidden_cat)\n",
    "        sigma_hat = self.fc_sigma(hidden_cat)\n",
    "        sigma = torch.exp(sigma_hat / 2)\n",
    "        z_size = mu.size()\n",
    "        if args.cuda:\n",
    "            N = Variable(torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda())\n",
    "        else:\n",
    "            N = Variable(torch.normal(torch.zeros(z_size),torch.ones(z_size)))\n",
    "        z = mu + sigma*N\n",
    "        return z, mu, sigma_hat\n",
    "\n",
    "\n",
    "\n",
    "    def init_hidden_cell(self):\n",
    "        hidden = Variable(torch.zeros(self.directions * args.n_layers, args.batch_size, args.encoder_h_dim))\n",
    "        cell = Variable(torch.zeros(self.directions * args.n_layers, args.batch_size, args.encoder_h_dim))\n",
    "        if args.cuda:\n",
    "            return (hidden.cuda(), cell.cuda())\n",
    "        else:\n",
    "            return (hidden, cell)\n",
    "\n",
    "class SketchRNNDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SketchRNNDecoder, self).__init__()\n",
    "        # to init hidden and cell from z:\n",
    "        self.fc_hc = nn.Linear(args.z_dim, 2 * args.n_layers * args.decoder_h_dim)\n",
    "        # unidirectional lstm:\n",
    "        self.lstm = nn.LSTM(args.z_dim + args.output_dim, args.decoder_h_dim, args.n_layers, dropout=args.decoder_layer_dropout)\n",
    "        self.muLayer = nn.Linear(args.decoder_h_dim, args.output_dim * args.n_gaussians)\n",
    "        self.sigmaLayer = nn.Linear(args.decoder_h_dim, args.output_dim * args.n_gaussians)\n",
    "        self.piLayer = nn.Linear(args.decoder_h_dim, args.output_dim * args.n_gaussians)\n",
    "\n",
    "    def forward(self, inputs, z, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            layers = torch.split(torch.tanh(self.fc_hc(z)),args.decoder_h_dim,1)\n",
    "            hidden = torch.stack(layers[:int(len(layers) / 2)], dim=0)\n",
    "            cell = torch.stack(layers[int(len(layers) / 2): ], dim=0)\n",
    "            hidden_cell = (hidden.contiguous(), cell.contiguous())\n",
    "        outputs,(hidden,cell) = self.lstm(inputs, hidden_cell)\n",
    "        # outputs size: (seq_len, batch, num_directions * hidden_size)\n",
    "        # hidden size: (num_layers * num_directions, batch, hidden_size)\n",
    "        # cell size: (num_layers * num_directions, batch, hidden_size)\n",
    "        mu = self.muLayer(outputs).view(-1, args.batch_size, args.output_dim, args.n_gaussians)\n",
    "        sigma = self.sigmaLayer(outputs).view(-1, args.batch_size, args.output_dim, args.n_gaussians)\n",
    "        pi = self.piLayer(outputs).view(-1, args.batch_size, args.output_dim, args.n_gaussians)\n",
    "        pi = F.softmax(pi, 3)\n",
    "        sigma = torch.exp(sigma)\n",
    "        return (pi, mu, sigma), (hidden, cell)\n",
    "\n",
    "class SketchRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SketchRNN, self).__init__()\n",
    "        if args.cuda:\n",
    "            self.encoder = SketchRNNEncoder().cuda()\n",
    "            self.decoder = SketchRNNDecoder().cuda()\n",
    "        else:\n",
    "            self.encoder = SketchRNNEncoder()\n",
    "            self.decoder = SketchRNNDecoder()\n",
    "\n",
    "    def scheduleSample(self, epoch):\n",
    "        eps = max(args.scheduling_start - \n",
    "            (args.scheduling_start - args.scheduling_end)* epoch / args.args.n_epochs,\n",
    "            args.scheduling_end)\n",
    "        return np.random.binomial(1, eps)\n",
    "\n",
    "    def generatePred(self, pi, mu, sigma):\n",
    "        if args.cuda:\n",
    "            N = Variable(torch.normal(torch.zeros(pi.size()),torch.ones(pi.size())).cuda())\n",
    "        else:\n",
    "            N = Variable(torch.normal(torch.zeros(pi.size()),torch.ones(pi.size())))\n",
    "        clusterPredictions = mu + sigma * N\n",
    "        weightedClusterPredictions = clusterPredictions * pi\n",
    "        pred = torch.sum(weightedClusterPredictions, dim=3)\n",
    "        return pred\n",
    "\n",
    "    def allSteps(self, target, z):\n",
    "        sos = self.getStartOfSequence()\n",
    "        batch_init = torch.cat([sos, target[:-1,...]], 0)\n",
    "        z_stack = torch.stack([z]*(args.sequence_len))\n",
    "        inp = torch.cat([batch_init, z_stack], 2)\n",
    "        (pi, mu, sigma), (hidden, cell) = self.decoder(inp, z)\n",
    "        return (pi, mu, sigma)\n",
    "\n",
    "    def oneStepAtATime(self, z):\n",
    "        sos = self.getStartOfSequence()\n",
    "        inp = torch.cat([sos, z.unsqueeze(0)], 2)\n",
    "        piList, muList, sigmaList = [], [], []\n",
    "        for timeStep in range(args.sequence_len):\n",
    "            (pi, mu, sigma), (hidden, cell) = self.decoder(inp, z)\n",
    "            pred = self.generatePred(pi, mu, sigma)\n",
    "            inp = torch.cat([pred, z.unsqueeze(0)], 2)\n",
    "            piList.append(pi)\n",
    "            muList.append(mu)\n",
    "            sigmaList.append(sigma)\n",
    "        Pi = torch.cat(piList, 0)\n",
    "        Mu = torch.cat(muList, 0)\n",
    "        Sigma = torch.cat(sigmaList, 0)\n",
    "        return (Pi, Mu, Sigma)\n",
    "\n",
    "    def getStartOfSequence(self):\n",
    "        if args.cuda:\n",
    "            return Variable(torch.zeros(1, args.batch_size, args.output_dim).cuda())\n",
    "        else:\n",
    "            return Variable(torch.zeros(1, args.batch_size, args.output_dim))\n",
    "\n",
    "    def doEncoding(self,batch):\n",
    "        # convert input from [sequence_len, batch_size, channels, x_dim]\n",
    "        #                 to [sequence_len, batch_size, channels * x_dim]\n",
    "        embedded = batch.contiguous().view(-1, args.batch_size, args.x_dim * args.channels)\n",
    "        z, mu, sigma_hat = self.encoder(embedded)\n",
    "        return z, mu, sigma_hat, embedded\n",
    "\n",
    "    def forward(self, batch, target):\n",
    "        z, latentMean, latentStd, embedded = self.doEncoding(embedded)\n",
    "        if self.training:\n",
    "            (Pi, Mu, Sigma) = self.allSteps(target, z)\n",
    "        else:\n",
    "            (Pi, Mu, Sigma) = self.oneStepAtATime(z)\n",
    "        return Pi, Mu, Sigma, latentMean, latentStd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load ../batchedRNN/utils.py\n",
    "import logging, sys\n",
    "import torch\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.utils.data as torchUtils\n",
    "import torch.optim as optim\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from shutil import copy2, copyfile, copytree\n",
    "import argparse\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Batched Sequence to Sequence')\n",
    "# parser.add_argument('--h_dim', type=int, default=256)\n",
    "# parser.add_argument(\"--z_dim\", type=int, default=128)\n",
    "# parser.add_argument('--no_cuda', action='store_true', default=False,\n",
    "#                                         help='disables CUDA training')\n",
    "# parser.add_argument(\"--no_attn\", action=\"store_true\", default=True, help=\"Do not use AttnDecoder\")\n",
    "# parser.add_argument(\"--n_epochs\", type=int, default=200)\n",
    "# parser.add_argument(\"--batch_size\", type=int, default= 64)\n",
    "# parser.add_argument(\"--n_layers\", type=int, default=2)\n",
    "# parser.add_argument(\"--initial_lr\", type=float, default=1e-4)\n",
    "# parser.add_argument(\"--lr_decay_every\", type=int, default=10)\n",
    "# parser.add_argument(\"--lr_decay_factor\", type=float, default=.10)\n",
    "# parser.add_argument(\"--lr_decay_beginning\", type=int, default=20)\n",
    "# parser.add_argument(\"--print_every\", type=int, default = 200)\n",
    "# parser.add_argument(\"--criterion\", type=str, default=\"L1Loss\")\n",
    "# parser.add_argument(\"--save_freq\", type=int, default=10)\n",
    "# parser.add_argument(\"--down_sample\", type=float, default=0.0, help=\"Keep this fraction of the training data\")\n",
    "# # parser.add_argument(\"--data_dir\", type=str, default=\"./data/reformattedTraffic/\")\n",
    "# parser.add_argument(\"--model\", type=str, default=\"sketch-rnn\")\n",
    "# parser.add_argument(\"--lambda_l1\", type=float, default=0)\n",
    "# parser.add_argument(\"--lambda_l2\", type=float, default=5e-4)\n",
    "# parser.add_argument(\"--no_schedule_sampling\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--scheduling_start\", type=float, default=1.0)\n",
    "# parser.add_argument(\"--scheduling_end\", type=float, default=0.0)\n",
    "# parser.add_argument(\"--tries\", type=int, default=12)\n",
    "# parser.add_argument(\"--kld_warmup_until\", type=int, default=5)\n",
    "# parser.add_argument(\"--kld_weight_max\", type=float, default=0.10)\n",
    "# parser.add_argument(\"--no_shuffle_after_epoch\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--clip\", type=int, default=10)\n",
    "# parser.add_argument(\"--dataset\", type=str, default=\"traffic\")\n",
    "# parser.add_argument(\"--predictOnTest\", action=\"store_true\", default=True)\n",
    "# parser.add_argument(\"--encoder_input_dropout\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--encoder_layer_dropout\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--decoder_input_dropout\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--decoder_layer_dropout\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--noEarlyStopping\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--earlyStoppingPatients\", type=int, default=3)\n",
    "# parser.add_argument(\"--earlyStoppingMinDelta\", type=float, default=0.0001)\n",
    "# parser.add_argument(\"--bidirectionalEncoder\", type=bool, default=True)\n",
    "# parser.add_argument(\"--local\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--debugDataset\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--encoder_h_dim\", type=int, default=256)\n",
    "# parser.add_argument(\"--decoder_h_dim\", type=int, default=512)\n",
    "# parser.add_argument(\"--num_mixtures\", type=int, default=20)\n",
    "# args = parser.parse_args()\n",
    "logging.basicConfig(stream=sys.stderr,level=logging.DEBUG)\n",
    "\n",
    "def plotLosses(trainLosses, valLosses, trainKLDLosses=None, valKLDLosses=None):\n",
    "    torch.save(trainLosses, args.save_dir+\"plot_train_recon_losses\")\n",
    "    torch.save(valLosses, args.save_dir+\"plot_val_recon_losses\")\n",
    "    if trainKLDLosses and valKLDLosses:\n",
    "        torch.save(trainKLDLosses, args.save_dir+\"plot_train_KLD_losses\")\n",
    "        torch.save(valKLDLosses, args.save_dir+\"plot_val_KLD_losses\")\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(args.criterion, color=\"r\")\n",
    "    ax1.tick_params('y', colors='r')\n",
    "    ax1.plot(np.arange(1, len(trainLosses)+1), trainLosses, \"r--\", label=\"train reconstruction loss\")\n",
    "    ax1.plot(np.arange(1, len(valLosses)+1), valLosses, color=\"red\", label=\"validation reconstruction loss\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.grid()\n",
    "    plt.title(\"Losses for {}\".format(args.model))\n",
    "    plt.savefig(args.save_dir + \"train_val_loss_plot.png\")\n",
    "\n",
    "def getSaveDir():\n",
    "    if args.local:\n",
    "        saveDir = '../save/local/models/model0/'\n",
    "    else:\n",
    "        saveDir = '../save/models/model0/'\n",
    "    while os.path.isdir(saveDir):\n",
    "        numStart = saveDir.rfind(\"model\")+5\n",
    "        numEnd = saveDir.rfind(\"/\")\n",
    "        saveDir = saveDir[:numStart] + str(int(saveDir[numStart:numEnd])+1) + \"/\"\n",
    "    os.mkdir(saveDir)\n",
    "    return saveDir\n",
    "\n",
    "def saveUsefulData():\n",
    "    argsFile = args.save_dir + \"args.txt\"\n",
    "    with open(argsFile, \"w\") as f:\n",
    "        f.write(json.dumps(vars(args)))\n",
    "    copy2(\"./train.py\", args.save_dir+\"train.py\")\n",
    "    copy2(\"./utils.py\", args.save_dir+\"utils.py\")\n",
    "    copy2(\"./gridSearchOptimize.py\", args.save_dir+\"gridsearchOptimize.py\")\n",
    "    copytree(\"./model\", args.save_dir+\"model/\")\n",
    "\n",
    "def getTrafficDataset(dataDir, category):\n",
    "    f = np.load(os.path.join(dataDir, category + '.npz'))\n",
    "    my_dataset = torchUtils.TensorDataset(torch.Tensor(f[\"inputs\"]),torch.Tensor(f[\"targets\"])) # create your datset\n",
    "    scaler = getScaler(f[\"inputs\"])\n",
    "    sequence_len = f['inputs'].shape[1]\n",
    "    x_dim = f['inputs'].shape[2]\n",
    "    channels = f[\"inputs\"].shape[3]\n",
    "    return my_dataset, scaler, sequence_len, sequence_len, x_dim, channels\n",
    "\n",
    "def getHumanDataset(dataDir, category):\n",
    "    f = h5py.File(os.path.join(dataDir, category+\".h5\"), \"r\")\n",
    "    my_dataset = torchUtils.TensorDataset(torch.Tensor(f[\"input2d\"]), torch.Tensor(f[\"target2d\"]))\n",
    "    scaler = getScaler(f[\"input2d\"])\n",
    "    input_sequence_len = f[\"input2d\"].shape[1]\n",
    "    target_sequence_len = f[\"target2d\"].shape[1]\n",
    "    x_dim = f[\"input2d\"].shape[2]\n",
    "    channels = f[\"input2d\"].shape[3]\n",
    "    return my_dataset, scaler, input_sequence_len, target_sequence_len, x_dim, channels\n",
    "\n",
    "def getLoaderAndScaler(dataDir, category):\n",
    "    logging.info(\"Getting {} loader\".format(category))\n",
    "    if args.dataset == \"traffic\":\n",
    "        my_dataset, scaler, input_sequence_len, target_sequence_len, x_dim, channels = getTrafficDataset(dataDir, category)\n",
    "    else:\n",
    "        my_dataset, scaler, input_sequence_len, target_sequence_len, x_dim, channels = getHumanDataset(dataDir, category)\n",
    "    shf = False\n",
    "    if category == \"train\":\n",
    "        shf = True\n",
    "    loader = torchUtils.DataLoader(\n",
    "        my_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=shf,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "        drop_last=True\n",
    "        )\n",
    "    return loader, scaler, input_sequence_len, target_sequence_len, x_dim, channels # create your dataloader\n",
    "\n",
    "def getDataLoaders(dataDir, debug=False):\n",
    "    loaders = {}\n",
    "    logging.info(\"Getting data from {}\".format(dataDir))\n",
    "    if debug:\n",
    "        categories = [\"test\"]\n",
    "        scalerSet = \"test\"\n",
    "    else:\n",
    "        categories = [\"train\", \"val\", \"test\"]\n",
    "        scalerSet = \"train\"\n",
    "    for category in categories:\n",
    "        loader, scaler, input_sequence_len, target_sequence_len, x_dim, channels = getLoaderAndScaler(dataDir, category)\n",
    "        if category == scalerSet:\n",
    "            loaders[\"scaler\"] = scaler\n",
    "            loaders[\"input_sequence_len\"] = input_sequence_len\n",
    "            loaders[\"target_sequence_len\"] = target_sequence_len\n",
    "            loaders[\"x_dim\"] = x_dim\n",
    "            loaders[\"channels\"] = channels\n",
    "        loaders[category] = loader\n",
    "    return loaders\n",
    "\n",
    "class StandardScaler:\n",
    "    \"\"\"\n",
    "    Standard the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean0, std0, mean1, std1):\n",
    "        self.mean0 = mean0\n",
    "        self.std0 = std0\n",
    "        self.mean1 = mean1\n",
    "        self.std1 = std1\n",
    "\n",
    "    def transform(self, data):\n",
    "        mean = torch.zeros(data.size())\n",
    "        mean[...,0] = self.mean0\n",
    "        mean[...,1] = self.mean1\n",
    "        std = torch.ones(data.size())\n",
    "        std[...,0] = self.std0\n",
    "        std[...,1] = self.std1\n",
    "        return torch.div(torch.sub(data,mean),std)\n",
    "\n",
    "class StandardScalerTraffic(StandardScaler):\n",
    "    def __init__(self, mean0, std0):\n",
    "        super(StandardScalerTraffic, self).__init__(mean0, std0, 0.0, 1.0)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        \"\"\"\n",
    "        Inverse transform is applied to output and target.\n",
    "        These are only the speeds, so only use the first \n",
    "        \"\"\"\n",
    "        mean = torch.ones(data.size()) * self.mean0\n",
    "        std = torch.ones(data.size()) * self.std0\n",
    "        if args.cuda:\n",
    "            mean = mean.cuda()\n",
    "            std = std.cuda()\n",
    "        transformed = torch.add(torch.mul(data, std), mean)\n",
    "        del mean, std\n",
    "        return transformed.permute(1,0,2)\n",
    "\n",
    "    def transformBatchForEpoch(self, batch):\n",
    "        x = self.transform(batch[0]).permute(1,0,3,2)\n",
    "        y = self.transform(batch[1])[...,0].permute(1,0,2)\n",
    "        if args.cuda:\n",
    "            return x.cuda(), y.cuda()\n",
    "        return x, y\n",
    "\n",
    "class StandardScalerHuman(StandardScaler):\n",
    "    \"\"\"docstring for StandardScalerHuman\"\"\"\n",
    "    def __init__(self, mean0, std0, mean1, std1):\n",
    "        super(StandardScalerHuman, self).__init__(mean0, std0, mean1, std1)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        \"\"\"\n",
    "        applied to output and target\n",
    "        \"\"\"\n",
    "        transed = self.restoreDim(data)\n",
    "        mean = torch.zeros(transed.size())\n",
    "        std = torch.ones(transed.size())\n",
    "        if args.cuda:\n",
    "            mean = mean.cuda()\n",
    "            std = std.cuda()\n",
    "        mean[...,0] = self.mean0\n",
    "        mean[...,1] = self.mean1\n",
    "        std[...,0] = self.std0\n",
    "        std[...,1] = self.std1\n",
    "        transformed =  torch.add(torch.mul(transed, std), mean)\n",
    "        del mean, std\n",
    "        return transformed.permute(1,0,3,2)\n",
    "\n",
    "    def restoreDim(self, data):\n",
    "        l1, l2 = torch.split(data, int(data.size(2) / 2), 2)\n",
    "        return torch.cat((l1.unsqueeze(3), l2.unsqueeze(3)), dim=3)\n",
    "\n",
    "    def removeDim(self, data):\n",
    "        layer0, layer1 = torch.split(data, 1, dim=3)\n",
    "        return torch.cat((layer0.squeeze(3), layer1.squeeze(3)), dim=2)\n",
    "\n",
    "    def transformBatchForEpoch(self, batch):\n",
    "        x = self.transform(batch[0]).permute(1,0,3,2)\n",
    "        y = self.transform(batch[1])\n",
    "        wideY = self.removeDim(y).permute(1,0,2)\n",
    "        if args.cuda:\n",
    "            return x.cuda(), wideY.cuda()\n",
    "        return x, wideY\n",
    "\n",
    "def getScaler(trainX):\n",
    "    mean0 = np.mean(trainX[...,0])\n",
    "    std0 = np.std(trainX[...,0])\n",
    "    mean1 = np.mean(trainX[...,1])\n",
    "    std1 = np.std(trainX[...,1])\n",
    "    if args.dataset == \"traffic\":\n",
    "        return StandardScalerTraffic(mean0, std0)\n",
    "    elif args.dataset == \"human\":\n",
    "        return StandardScalerHuman(mean0, std0, mean1, std1)\n",
    "    else:\n",
    "        assert False, \"bad dataset\"\n",
    "\n",
    "def getReconLoss(output, target, scaler):\n",
    "    output = scaler.inverse_transform(output)\n",
    "    target = scaler.inverse_transform(target)\n",
    "    assert output.size() == target.size(), \"output size: {}, target size: {}\".format(output.size(), target.size())\n",
    "    if args.criterion == \"RMSE\":\n",
    "        criterion = nn.MSELoss()\n",
    "        return torch.sqrt(criterion(output, target))\n",
    "    elif args.criterion == \"L1Loss\":\n",
    "        criterion = nn.L1Loss()\n",
    "        return criterion(output, target)\n",
    "    else:\n",
    "        assert False, \"bad loss function\"\n",
    "\n",
    "def getKLDWeight(epoch):\n",
    "    # kldLossWeight = args.kld_weight_max * min((epoch / (args.kld_warmup_until)), 1.0)\n",
    "    kldLossWeight = args.kld_weight_max\n",
    "    return kldLossWeight\n",
    "\n",
    "def kld_gauss(mean_1, std_1, mean_2, std_2):\n",
    "    \"\"\"Using std to compute KLD\"\"\"\n",
    "\n",
    "    kld_element = (2 * torch.log(std_2) - 2 * torch.log(std_1) +\n",
    "                   (std_1.pow(2) + (mean_1 - mean_2).pow(2)) /\n",
    "                   std_2.pow(2) - 1)\n",
    "    return 0.5 * torch.sum(kld_element)\n",
    "\n",
    "def sketchRNNKLD(latentMean, latentStd):\n",
    "    m2 = torch.zeros_like(latentMean)\n",
    "    s2 = torch.ones_like(latentStd)\n",
    "    return kld_gauss(latentMean, latentStd, m2, s2)\n",
    "\n",
    "def getLoss(model, output, target, scaler, epoch):\n",
    "    if args.model == \"rnn\":\n",
    "        reconLoss = getReconLoss(output, target, scaler)\n",
    "        return reconLoss, 0\n",
    "    else:\n",
    "        latentMean, latentStd, z, predOut, predMeanOut, predStdOut = output\n",
    "        reconLoss = getReconLoss(predOut, target, scaler)\n",
    "        kldLoss = sketchRNNKLD(latentMean, latentStd)\n",
    "        return reconLoss, kldLoss\n",
    "\n",
    "def saveModel(modelWeights, epoch):\n",
    "    fn = args.save_dir+'{}_state_dict_'.format(args.model)+str(epoch)+'.pth'\n",
    "    torch.save(modelWeights, fn)\n",
    "    logging.info('Saved model to '+fn)\n",
    "\n",
    "class EarlyStoppingObject(object):\n",
    "    \"\"\"docstring for EarlyStoppingObject\"\"\"\n",
    "    def __init__(self):\n",
    "        super(EarlyStoppingObject, self).__init__()\n",
    "        self.bestLoss = None\n",
    "        self.bestEpoch = None\n",
    "        self.counter = 0\n",
    "        self.epochCounter = 0\n",
    "\n",
    "    def checkStop(self, previousLoss):\n",
    "        self.epochCounter += 1\n",
    "        if not args.noEarlyStopping:\n",
    "            if self.bestLoss is not None and previousLoss + args.earlyStoppingMinDelta >= self.bestLoss:\n",
    "                self.counter += 1\n",
    "                if self.counter >= args.earlyStoppingPatients:\n",
    "                    logging.info(\"Stopping Early, haven't beaten best loss {:.4f} @ Epoch {} in {} epochs\".format(\n",
    "                        self.bestLoss,\n",
    "                        self.bestEpoch,\n",
    "                        args.earlyStoppingPatients))\n",
    "                    return True\n",
    "            else:\n",
    "                self.bestLoss = previousLoss\n",
    "                self.bestEpoch = self.epochCounter\n",
    "                self.counter = 0\n",
    "                return False\n",
    "\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run GetLossObj.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = \"../save/local/models/model21/\"\n",
    "with open(baseDir + \"args.txt\") as f:\n",
    "    args = f.read()\n",
    "args = Bunch(json.loads(args))\n",
    "args.encoder_h_dim = args.h_dim\n",
    "args.decoder_h_dim = args.h_dim\n",
    "args.z_dim = 128\n",
    "args.cuda= False\n",
    "args.sequence_len = 12\n",
    "args.n_gaussians = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_dim: 256, z_dim: 128, no_cuda: False, no_attn: True, n_epochs: 20, batch_size: 64, n_layers: 2, initial_lr: 0.0001, lr_decay_every: 10, lr_decay_factor: 0.1, lr_decay_beginning: 20, print_every: 10, criterion: L1Loss, save_freq: 10, down_sample: 0.0, model: rnn, lambda_l1: 0, lambda_l2: 0.0005, no_schedule_sampling: True, scheduling_start: 1.0, scheduling_end: 0.0, tries: 12, kld_warmup_until: 5, kld_weight_max: 0.1, no_shuffle_after_epoch: False, clip: 10, dataset: traffic, predictOnTest: True, encoder_input_dropout: 0.5, encoder_layer_dropout: 0.5, decoder_input_dropout: 0.5, decoder_layer_dropout: 0.5, noEarlyStopping: True, earlyStoppingPatients: 3, earlyStoppingMinDelta: 0.0001, bidirectionalEncoder: True, local: True, debugDataset: True, cuda: False, _device: cpu, use_attn: False, use_schedule_sampling: False, x_dim: 207, input_sequence_len: 12, target_sequence_len: 12, channels: 2, output_dim: 207, save_dir: ../save/local/models/model21/, encoder_h_dim: 256, decoder_h_dim: 256, sequence_len: 12, n_gaussians: 20, \n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Getting data from /Users/danielzeiberg/Documents/Data/Traffic/Processed/trafficWithTime/down_sample_0.1/\n",
      "INFO:root:Getting train loader\n",
      "INFO:root:Getting val loader\n",
      "INFO:root:Getting test loader\n"
     ]
    }
   ],
   "source": [
    "data = getDataLoaders(\"/Users/danielzeiberg/Documents/Data/Traffic/Processed/trafficWithTime/down_sample_0.1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch = SketchRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inputData, target) = next(map(data[\"scaler\"].transformBatchForEpoch, data[\"train\"]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 64, 2, 207]), torch.Size([12, 64, 207]))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, latentMean, latentStd, embedded = sketch.doEncoding(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 128]),\n",
       " torch.Size([64, 128]),\n",
       " torch.Size([64, 128]),\n",
       " torch.Size([12, 64, 414]))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape, latentMean.shape, latentStd.shape, embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 207])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sketch.getStartOfSequence().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi, Mu, Sigma = sketch.allSteps(target, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 64, 207, 20]),\n",
       " torch.Size([12, 64, 207, 20]),\n",
       " torch.Size([12, 64, 207, 20]))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pi.shape, Mu.shape, Sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "PiOne, MuOne, SigmaOne = sketch.oneStepAtATime(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 64, 207, 20]),\n",
       " torch.Size([12, 64, 207, 20]),\n",
       " torch.Size([12, 64, 207, 20]))"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PiOne.shape, MuOne.shape, SigmaOne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.distributions.Normal(loc=Mu, scale=Sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64, 207, 20])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackedTarget = torch.stack([target]*Mu.size(3), dim=3)\n",
    "loss = torch.exp(m.log_prob(stackedTarget))\n",
    "loss.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64, 207, 20])\n",
      "torch.Size([12, 64, 207])\n"
     ]
    }
   ],
   "source": [
    "weightedLoss = loss * Pi\n",
    "print(weightedLoss.size())\n",
    "loss = torch.sum(weightedLoss, dim=3)\n",
    "print(loss.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64, 207])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss= -torch.log(loss)\n",
    "loss.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3814, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
