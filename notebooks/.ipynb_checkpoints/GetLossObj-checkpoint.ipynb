{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load ../batchedRNN/model/Data.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    " \n",
    "class DataLoader(object):\n",
    "    def __init__(self, xs, ys, batch_size, pad_with_last_sample=True, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.current_ind = 0\n",
    "        if pad_with_last_sample:\n",
    "            num_padding = (batch_size - (len(xs) % batch_size)) % batch_size\n",
    "            x_padding = np.repeat(xs[-1:], num_padding, axis=0)\n",
    "            y_padding = np.repeat(ys[-1:], num_padding, axis=0)\n",
    "            xs = np.concatenate([xs, x_padding], axis=0)\n",
    "            ys = np.concatenate([ys, y_padding], axis=0)\n",
    "        self.size = len(xs)\n",
    "        self.num_batch = int(self.size // self.batch_size)\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        if shuffle:\n",
    "            self.shuffle()\n",
    "\n",
    "    def get_iterator(self):\n",
    "        self.current_ind = 0\n",
    "\n",
    "        def _wrapper():\n",
    "            while self.current_ind < self.num_batch:\n",
    "                start_ind = self.batch_size * self.current_ind\n",
    "                end_ind = min(self.size, self.batch_size * (self.current_ind + 1))\n",
    "                x_i = np.transpose(self.xs[start_ind: end_ind, ...], (1,0,3,2))\n",
    "                y_i = np.transpose(self.ys[start_ind: end_ind, :,:,0], (1,0,2))\n",
    "                yield (x_i, y_i)\n",
    "                self.current_ind += 1\n",
    "\n",
    "        return _wrapper()\n",
    "\n",
    "\n",
    "    def shuffle(self):\n",
    "        permutation = np.random.permutation(self.size)\n",
    "        self.xs, self.ys = self.xs[permutation], self.ys[permutation]\n",
    "\n",
    "class DataLoaderWithTime(object):\n",
    "    def __init__(self, xs, ys, tx, ty, batch_size, pad_with_last_sample=True, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.current_ind = 0\n",
    "        if pad_with_last_sample:\n",
    "            num_padding = (batch_size - (len(xs) % batch_size)) % batch_size\n",
    "            x_padding = np.repeat(xs[-1:], num_padding, axis=0)\n",
    "            y_padding = np.repeat(ys[-1:], num_padding, axis=0)\n",
    "            tx_padding = np.repeat(tx[-1:], num_padding, axis=0)\n",
    "            ty_padding = np.repeat(ty[-1:], num_padding, axis=0)\n",
    "            xs = np.concatenate([xs, x_padding], axis=0)\n",
    "            ys = np.concatenate([ys, y_padding], axis=0)\n",
    "            tx = np.concatenate([tx, tx_padding], axis=0)\n",
    "            ty = np.concatenate([ty, ty_padding], axis=0)\n",
    "        self.size = len(xs)\n",
    "        self.num_batch = int(self.size // self.batch_size)\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        self.tx = tx\n",
    "        self.ty = ty\n",
    "        if shuffle:\n",
    "            self.shuffle()\n",
    "\n",
    "    def get_iterator(self):\n",
    "        self.current_ind = 0\n",
    "\n",
    "        def _wrapper():\n",
    "            while self.current_ind < self.num_batch:\n",
    "                start_ind = self.batch_size * self.current_ind\n",
    "                end_ind = min(self.size, self.batch_size * (self.current_ind + 1))\n",
    "                x_i = np.transpose(self.xs[start_ind: end_ind, ...], (1,0,3,2))\n",
    "                y_i = np.transpose(self.ys[start_ind: end_ind, :,:,0], (1,0,2))\n",
    "                tx_i = np.transpose(self.tx[start_ind: end_ind, ...], (1,0))\n",
    "                ty_i = np.transpose(self.ty[start_ind: end_ind, ...], (1,0))\n",
    "                yield (x_i, y_i, tx_i, ty_i)\n",
    "                self.current_ind += 1\n",
    "\n",
    "        return _wrapper()\n",
    "\n",
    "    def shuffle(self):\n",
    "        permutation = np.random.permutation(self.size)\n",
    "        self.xs, self.ys, self.tx, self.ty = self.xs[permutation], self.ys[permutation], self.tx[permutation], self.ty[permutation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load ../batchedRNN/utils.py\n",
    "import logging, sys\n",
    "import torch\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.utils.data as torchUtils\n",
    "import torch.optim as optim\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from shutil import copy2, copyfile, copytree\n",
    "import argparse\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Batched Sequence to Sequence')\n",
    "# parser.add_argument('--h_dim', type=int, default=256)\n",
    "# parser.add_argument(\"--z_dim\", type=int, default=128)\n",
    "# parser.add_argument('--no_cuda', action='store_true', default=False,\n",
    "#                                         help='disables CUDA training')\n",
    "# parser.add_argument(\"--no_attn\", action=\"store_true\", default=True, help=\"Do not use AttnDecoder\")\n",
    "# parser.add_argument(\"--n_epochs\", type=int, default=200)\n",
    "# parser.add_argument(\"--batch_size\", type=int, default= 64)\n",
    "# parser.add_argument(\"--n_layers\", type=int, default=2)\n",
    "# parser.add_argument(\"--initial_lr\", type=float, default=1e-4)\n",
    "# parser.add_argument(\"--lr_decay_every\", type=int, default=10)\n",
    "# parser.add_argument(\"--lr_decay_factor\", type=float, default=.10)\n",
    "# parser.add_argument(\"--lr_decay_beginning\", type=int, default=20)\n",
    "# parser.add_argument(\"--print_every\", type=int, default = 200)\n",
    "# parser.add_argument(\"--criterion\", type=str, default=\"L1Loss\")\n",
    "# parser.add_argument(\"--save_freq\", type=int, default=10)\n",
    "# parser.add_argument(\"--down_sample\", type=float, default=0.0, help=\"Keep this fraction of the training data\")\n",
    "# # parser.add_argument(\"--data_dir\", type=str, default=\"./data/reformattedTraffic/\")\n",
    "# parser.add_argument(\"--model\", type=str, default=\"sketch-rnn\")\n",
    "# parser.add_argument(\"--lambda_l1\", type=float, default=0)\n",
    "# parser.add_argument(\"--lambda_l2\", type=float, default=5e-4)\n",
    "# parser.add_argument(\"--no_schedule_sampling\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--scheduling_start\", type=float, default=1.0)\n",
    "# parser.add_argument(\"--scheduling_end\", type=float, default=0.0)\n",
    "# parser.add_argument(\"--tries\", type=int, default=12)\n",
    "# parser.add_argument(\"--kld_warmup_until\", type=int, default=5)\n",
    "# parser.add_argument(\"--kld_weight_max\", type=float, default=0.10)\n",
    "# parser.add_argument(\"--no_shuffle_after_epoch\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--clip\", type=int, default=10)\n",
    "# parser.add_argument(\"--dataset\", type=str, default=\"traffic\")\n",
    "# parser.add_argument(\"--predictOnTest\", action=\"store_true\", default=True)\n",
    "# parser.add_argument(\"--encoder_input_dropout\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--encoder_layer_dropout\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--decoder_input_dropout\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--decoder_layer_dropout\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--noEarlyStopping\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--earlyStoppingPatients\", type=int, default=3)\n",
    "# parser.add_argument(\"--earlyStoppingMinDelta\", type=float, default=0.0001)\n",
    "# parser.add_argument(\"--bidirectionalEncoder\", type=bool, default=True)\n",
    "# parser.add_argument(\"--local\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--debugDataset\", action=\"store_true\", default=False)\n",
    "# parser.add_argument(\"--encoder_h_dim\", type=int, default=256)\n",
    "# parser.add_argument(\"--decoder_h_dim\", type=int, default=512)\n",
    "# parser.add_argument(\"--num_mixtures\", type=int, default=20)\n",
    "# args = parser.parse_args()\n",
    "logging.basicConfig(stream=sys.stderr,level=logging.DEBUG)\n",
    "\n",
    "def plotLosses(trainLosses, valLosses, trainKLDLosses=None, valKLDLosses=None):\n",
    "    torch.save(trainLosses, args.save_dir+\"plot_train_recon_losses\")\n",
    "    torch.save(valLosses, args.save_dir+\"plot_val_recon_losses\")\n",
    "    if trainKLDLosses and valKLDLosses:\n",
    "        torch.save(trainKLDLosses, args.save_dir+\"plot_train_KLD_losses\")\n",
    "        torch.save(valKLDLosses, args.save_dir+\"plot_val_KLD_losses\")\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(args.criterion, color=\"r\")\n",
    "    ax1.tick_params('y', colors='r')\n",
    "    ax1.plot(np.arange(1, len(trainLosses)+1), trainLosses, \"r--\", label=\"train reconstruction loss\")\n",
    "    ax1.plot(np.arange(1, len(valLosses)+1), valLosses, color=\"red\", label=\"validation reconstruction loss\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.grid()\n",
    "    plt.title(\"Losses for {}\".format(args.model))\n",
    "    plt.savefig(args.save_dir + \"train_val_loss_plot.png\")\n",
    "\n",
    "def getSaveDir():\n",
    "    if args.local:\n",
    "        saveDir = '../save/local/models/model0/'\n",
    "    else:\n",
    "        saveDir = '../save/models/model0/'\n",
    "    while os.path.isdir(saveDir):\n",
    "        numStart = saveDir.rfind(\"model\")+5\n",
    "        numEnd = saveDir.rfind(\"/\")\n",
    "        saveDir = saveDir[:numStart] + str(int(saveDir[numStart:numEnd])+1) + \"/\"\n",
    "    os.mkdir(saveDir)\n",
    "    return saveDir\n",
    "\n",
    "def saveUsefulData():\n",
    "    argsFile = args.save_dir + \"args.txt\"\n",
    "    with open(argsFile, \"w\") as f:\n",
    "        f.write(json.dumps(vars(args)))\n",
    "    copy2(\"./train.py\", args.save_dir+\"train.py\")\n",
    "    copy2(\"./utils.py\", args.save_dir+\"utils.py\")\n",
    "    copy2(\"./gridSearchOptimize.py\", args.save_dir+\"gridsearchOptimize.py\")\n",
    "    copytree(\"./model\", args.save_dir+\"model/\")\n",
    "\n",
    "def getTrafficDataset(dataDir, category):\n",
    "    f = np.load(os.path.join(dataDir, category + '.npz'))\n",
    "    my_dataset = torchUtils.TensorDataset(torch.Tensor(f[\"inputs\"]),torch.Tensor(f[\"targets\"])) # create your datset\n",
    "    scaler = getScaler(f[\"inputs\"])\n",
    "    sequence_len = f['inputs'].shape[1]\n",
    "    x_dim = f['inputs'].shape[2]\n",
    "    channels = f[\"inputs\"].shape[3]\n",
    "    return my_dataset, scaler, sequence_len, sequence_len, x_dim, channels\n",
    "\n",
    "def getHumanDataset(dataDir, category):\n",
    "    f = h5py.File(os.path.join(dataDir, category+\".h5\"), \"r\")\n",
    "    my_dataset = torchUtils.TensorDataset(torch.Tensor(f[\"input2d\"]), torch.Tensor(f[\"target2d\"]))\n",
    "    scaler = getScaler(f[\"input2d\"])\n",
    "    input_sequence_len = f[\"input2d\"].shape[1]\n",
    "    target_sequence_len = f[\"target2d\"].shape[1]\n",
    "    x_dim = f[\"input2d\"].shape[2]\n",
    "    channels = f[\"input2d\"].shape[3]\n",
    "    return my_dataset, scaler, input_sequence_len, target_sequence_len, x_dim, channels\n",
    "\n",
    "def getLoaderAndScaler(dataDir, category):\n",
    "    logging.info(\"Getting {} loader\".format(category))\n",
    "    if args.dataset == \"traffic\":\n",
    "        my_dataset, scaler, input_sequence_len, target_sequence_len, x_dim, channels = getTrafficDataset(dataDir, category)\n",
    "    else:\n",
    "        my_dataset, scaler, input_sequence_len, target_sequence_len, x_dim, channels = getHumanDataset(dataDir, category)\n",
    "    shf = False\n",
    "    if category == \"train\":\n",
    "        shf = True\n",
    "    loader = torchUtils.DataLoader(\n",
    "        my_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=shf,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "        drop_last=True\n",
    "        )\n",
    "    return loader, scaler, input_sequence_len, target_sequence_len, x_dim, channels # create your dataloader\n",
    "\n",
    "def getDataLoaders(dataDir, debug=False):\n",
    "    loaders = {}\n",
    "    logging.info(\"Getting data from {}\".format(dataDir))\n",
    "    if debug:\n",
    "        categories = [\"test\"]\n",
    "        scalerSet = \"test\"\n",
    "    else:\n",
    "        categories = [\"train\", \"val\", \"test\"]\n",
    "        scalerSet = \"train\"\n",
    "    for category in categories:\n",
    "        loader, scaler, input_sequence_len, target_sequence_len, x_dim, channels = getLoaderAndScaler(dataDir, category)\n",
    "        if category == scalerSet:\n",
    "            loaders[\"scaler\"] = scaler\n",
    "            loaders[\"input_sequence_len\"] = input_sequence_len\n",
    "            loaders[\"target_sequence_len\"] = target_sequence_len\n",
    "            loaders[\"x_dim\"] = x_dim\n",
    "            loaders[\"channels\"] = channels\n",
    "        loaders[category] = loader\n",
    "    return loaders\n",
    "\n",
    "class StandardScaler:\n",
    "    \"\"\"\n",
    "    Standard the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean0, std0, mean1, std1):\n",
    "        self.mean0 = mean0\n",
    "        self.std0 = std0\n",
    "        self.mean1 = mean1\n",
    "        self.std1 = std1\n",
    "\n",
    "    def transform(self, data):\n",
    "        mean = torch.zeros(data.size())\n",
    "        mean[...,0] = self.mean0\n",
    "        mean[...,1] = self.mean1\n",
    "        std = torch.ones(data.size())\n",
    "        std[...,0] = self.std0\n",
    "        std[...,1] = self.std1\n",
    "        return torch.div(torch.sub(data,mean),std)\n",
    "\n",
    "class StandardScalerTraffic(StandardScaler):\n",
    "    def __init__(self, mean0, std0):\n",
    "        super(StandardScalerTraffic, self).__init__(mean0, std0, 0.0, 1.0)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        \"\"\"\n",
    "        Inverse transform is applied to output and target.\n",
    "        These are only the speeds, so only use the first \n",
    "        \"\"\"\n",
    "        mean = torch.ones(data.size()) * self.mean0\n",
    "        std = torch.ones(data.size()) * self.std0\n",
    "        if args.cuda:\n",
    "            mean = mean.cuda()\n",
    "            std = std.cuda()\n",
    "        transformed = torch.add(torch.mul(data, std), mean)\n",
    "        del mean, std\n",
    "        return transformed.permute(1,0,2)\n",
    "\n",
    "    def transformBatchForEpoch(self, batch):\n",
    "        x = self.transform(batch[0]).permute(1,0,3,2)\n",
    "        y = self.transform(batch[1])[...,0].permute(1,0,2)\n",
    "        if args.cuda:\n",
    "            return x.cuda(), y.cuda()\n",
    "        return x, y\n",
    "\n",
    "class StandardScalerHuman(StandardScaler):\n",
    "    \"\"\"docstring for StandardScalerHuman\"\"\"\n",
    "    def __init__(self, mean0, std0, mean1, std1):\n",
    "        super(StandardScalerHuman, self).__init__(mean0, std0, mean1, std1)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        \"\"\"\n",
    "        applied to output and target\n",
    "        \"\"\"\n",
    "        transed = self.restoreDim(data)\n",
    "        mean = torch.zeros(transed.size())\n",
    "        std = torch.ones(transed.size())\n",
    "        if args.cuda:\n",
    "            mean = mean.cuda()\n",
    "            std = std.cuda()\n",
    "        mean[...,0] = self.mean0\n",
    "        mean[...,1] = self.mean1\n",
    "        std[...,0] = self.std0\n",
    "        std[...,1] = self.std1\n",
    "        transformed =  torch.add(torch.mul(transed, std), mean)\n",
    "        del mean, std\n",
    "        return transformed.permute(1,0,3,2)\n",
    "\n",
    "    def restoreDim(self, data):\n",
    "        l1, l2 = torch.split(data, int(data.size(2) / 2), 2)\n",
    "        return torch.cat((l1.unsqueeze(3), l2.unsqueeze(3)), dim=3)\n",
    "\n",
    "    def removeDim(self, data):\n",
    "        layer0, layer1 = torch.split(data, 1, dim=3)\n",
    "        return torch.cat((layer0.squeeze(3), layer1.squeeze(3)), dim=2)\n",
    "\n",
    "    def transformBatchForEpoch(self, batch):\n",
    "        x = self.transform(batch[0]).permute(1,0,3,2)\n",
    "        y = self.transform(batch[1])\n",
    "        wideY = self.removeDim(y).permute(1,0,2)\n",
    "        if args.cuda:\n",
    "            return x.cuda(), wideY.cuda()\n",
    "        return x, wideY\n",
    "\n",
    "def getScaler(trainX):\n",
    "    mean0 = np.mean(trainX[...,0])\n",
    "    std0 = np.std(trainX[...,0])\n",
    "    mean1 = np.mean(trainX[...,1])\n",
    "    std1 = np.std(trainX[...,1])\n",
    "    if args.dataset == \"traffic\":\n",
    "        return StandardScalerTraffic(mean0, std0)\n",
    "    elif args.dataset == \"human\":\n",
    "        return StandardScalerHuman(mean0, std0, mean1, std1)\n",
    "    else:\n",
    "        assert False, \"bad dataset\"\n",
    "\n",
    "def getReconLoss(output, target, scaler):\n",
    "    output = scaler.inverse_transform(output)\n",
    "    target = scaler.inverse_transform(target)\n",
    "    assert output.size() == target.size(), \"output size: {}, target size: {}\".format(output.size(), target.size())\n",
    "    if args.criterion == \"RMSE\":\n",
    "        criterion = nn.MSELoss()\n",
    "        return torch.sqrt(criterion(output, target))\n",
    "    elif args.criterion == \"L1Loss\":\n",
    "        criterion = nn.L1Loss()\n",
    "        return criterion(output, target)\n",
    "    else:\n",
    "        assert False, \"bad loss function\"\n",
    "\n",
    "def getKLDWeight(epoch):\n",
    "    # kldLossWeight = args.kld_weight_max * min((epoch / (args.kld_warmup_until)), 1.0)\n",
    "    kldLossWeight = args.kld_weight_max\n",
    "    return kldLossWeight\n",
    "\n",
    "def kld_gauss(mean_1, std_1, mean_2, std_2):\n",
    "    \"\"\"Using std to compute KLD\"\"\"\n",
    "\n",
    "    kld_element = (2 * torch.log(std_2) - 2 * torch.log(std_1) +\n",
    "                   (std_1.pow(2) + (mean_1 - mean_2).pow(2)) /\n",
    "                   std_2.pow(2) - 1)\n",
    "    return 0.5 * torch.sum(kld_element)\n",
    "\n",
    "def sketchRNNKLD(latentMean, latentStd):\n",
    "    m2 = torch.zeros_like(latentMean)\n",
    "    s2 = torch.ones_like(latentStd)\n",
    "    return kld_gauss(latentMean, latentStd, m2, s2)\n",
    "\n",
    "def getLoss(model, output, target, scaler, epoch):\n",
    "    if args.model == \"rnn\":\n",
    "        reconLoss = getReconLoss(output, target, scaler)\n",
    "        return reconLoss, 0\n",
    "    else:\n",
    "        latentMean, latentStd, z, predOut, predMeanOut, predStdOut = output\n",
    "        reconLoss = getReconLoss(predOut, target, scaler)\n",
    "        kldLoss = sketchRNNKLD(latentMean, latentStd)\n",
    "        return reconLoss, kldLoss\n",
    "\n",
    "def saveModel(modelWeights, epoch):\n",
    "    fn = args.save_dir+'{}_state_dict_'.format(args.model)+str(epoch)+'.pth'\n",
    "    torch.save(modelWeights, fn)\n",
    "    logging.info('Saved model to '+fn)\n",
    "\n",
    "class EarlyStoppingObject(object):\n",
    "    \"\"\"docstring for EarlyStoppingObject\"\"\"\n",
    "    def __init__(self):\n",
    "        super(EarlyStoppingObject, self).__init__()\n",
    "        self.bestLoss = None\n",
    "        self.bestEpoch = None\n",
    "        self.counter = 0\n",
    "        self.epochCounter = 0\n",
    "\n",
    "    def checkStop(self, previousLoss):\n",
    "        self.epochCounter += 1\n",
    "        if not args.noEarlyStopping:\n",
    "            if self.bestLoss is not None and previousLoss + args.earlyStoppingMinDelta >= self.bestLoss:\n",
    "                self.counter += 1\n",
    "                if self.counter >= args.earlyStoppingPatients:\n",
    "                    logging.info(\"Stopping Early, haven't beaten best loss {:.4f} @ Epoch {} in {} epochs\".format(\n",
    "                        self.bestLoss,\n",
    "                        self.bestEpoch,\n",
    "                        args.earlyStoppingPatients))\n",
    "                    return True\n",
    "            else:\n",
    "                self.bestLoss = previousLoss\n",
    "                self.bestEpoch = self.epochCounter\n",
    "                self.counter = 0\n",
    "                return False\n",
    "\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load ../batchedRNN/model/RoseSeq2Seq\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=2, bidirectional=True, args=None):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.args = args\n",
    "        self.input_size = input_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * self.args.channels, hidden_size, n_layers, dropout=self.args.encoder_layer_dropout, bidirectional=bidirectional)\n",
    "        self.input_dropout = nn.Dropout(p=self.args.encoder_input_dropout)\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.input_dropout(embedded)\n",
    "        embedded = torch.unsqueeze(embedded, 0)\n",
    "        embedded = embedded.view(1, self.args.batch_size, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if self.args.bidirectionalEncoder:\n",
    "            directions = 2\n",
    "        else:\n",
    "            directions = 1\n",
    "        result = Variable(torch.zeros(self.n_layers * directions, self.args.batch_size, self.hidden_size))\n",
    "        if self.args.cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=2, args=None):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Linear(output_size, hidden_size)\n",
    "        self.input_dropout = nn.Dropout(p=self.args.decoder_input_dropout)\n",
    "        if self.args.bidirectionalEncoder:\n",
    "            directions = 2\n",
    "        else:\n",
    "            directions = 1\n",
    "        # encoder hidden is (layers * directions, batch, hidden_size)\n",
    "        # converted to (layers, batch, hidden_size * directions)\n",
    "        self.gru = nn.GRU(hidden_size, directions * hidden_size, n_layers, dropout=self.args.decoder_layer_dropout)\n",
    "        # GRU output (seq_len, batch, directions * hidden_size)\n",
    "        self.out = nn.Linear(directions * hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.input_dropout(embedded)\n",
    "        embedded = F.relu(embedded)\n",
    "        embedded = torch.unsqueeze(embedded, 0)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.out(output.squeeze(0))\n",
    "        #print(\"decoder output\", output[10,31])\n",
    "        return output, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.enc = EncoderRNN(self.args.x_dim, self.args.h_dim, n_layers=self.args.n_layers, bidirectional=args.bidirectionalEncoder, args=args)\n",
    "\n",
    "        self.dec = DecoderRNN(self.args.h_dim, self.args.output_dim, n_layers=self.args.n_layers, args=args)\n",
    "\n",
    "        self.use_schedule_sampling = args.use_schedule_sampling\n",
    "        self.scheduling_start = args.scheduling_start\n",
    "        self.scheduling_end = args.scheduling_end\n",
    "\n",
    "    def _cat_directions(self, h):\n",
    "        \"\"\" If the encoder is bidirectional, do the following transformation.\n",
    "            (#directions * #layers, #batch, hidden_size) -> (#layers, #batch, #directions * hidden_size)\n",
    "        \"\"\"\n",
    "        h = torch.cat([h[0:h.size(0):2], h[1:h.size(0):2]], 2)\n",
    "        return h\n",
    "\n",
    "    def parameters(self):\n",
    "        return list(self.enc.parameters()) + list(self.dec.parameters())\n",
    "\n",
    "    def scheduleSample(self, epoch):\n",
    "        eps = max(self.args.scheduling_start - \n",
    "            (self.args.scheduling_start - self.args.scheduling_end)* epoch / self.args.n_epochs,\n",
    "            self.args.scheduling_end)\n",
    "        return np.random.binomial(1, eps)\n",
    "\n",
    "    def forward(self, x, target, epoch):\n",
    "        encoder_hidden = self.enc.initHidden()\n",
    "        hs = []\n",
    "        for t in range(self.args.input_sequence_len):\n",
    "            encoder_output, encoder_hidden = self.enc(x[t].squeeze(), encoder_hidden)\n",
    "            hs += [encoder_output]\n",
    "        if self.args.bidirectionalEncoder:\n",
    "            decoder_hidden = self._cat_directions(encoder_hidden)\n",
    "        else:\n",
    "            decoder_hidden = encoder_hidden\n",
    "        # Prepare for Decoder\n",
    "        inp = Variable(torch.zeros(self.args.batch_size, self.args.output_dim))\n",
    "        if self.args.cuda:\n",
    "            inp = inp.cuda()\n",
    "        ys = []\n",
    "        if not self.training:\n",
    "            sample=0\n",
    "        else:\n",
    "            sample = self.scheduleSample(epoch)\n",
    "        # Decode\n",
    "        for t in range(self.args.target_sequence_len):\n",
    "            decoder_output, decoder_hidden = self.dec(inp, decoder_hidden)\n",
    "            if sample:\n",
    "                inp = target[t-1]\n",
    "            else:\n",
    "                inp = decoder_output\n",
    "            ys += [decoder_output]\n",
    "        return torch.cat([torch.unsqueeze(y, dim=0) for y in ys])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load ../batchedRNN/model/SketchRNN.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SketchRNNEncoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SketchRNNEncoder, self).__init__()\n",
    "        self.args = args\n",
    "        if self.args.bidirectionalEncoder:\n",
    "            self.directions = 2\n",
    "        else:\n",
    "            self.directions = 1\n",
    "        # bidirectional lstm:\n",
    "        self.lstm = nn.LSTM(self.args.x_dim * self.args.channels, self.args.encoder_h_dim, \\\n",
    "            self.args.n_layers, dropout=self.args.encoder_layer_dropout, bidirectional=self.args.bidirectionalEncoder)\n",
    "        # create mu and sigma from lstm's last output:\n",
    "        self.fc_mu = nn.Linear(self.args.n_layers * self.directions * self.args.encoder_h_dim, self.args.z_dim)\n",
    "        self.fc_sigma = nn.Linear(self.args.n_layers * self.directions * self.args.encoder_h_dim, self.args.z_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            hidden_cell = self.init_hidden_cell()\n",
    "        _, (hidden, cell) = self.lstm(input, hidden_cell)\n",
    "        # convert hidden size from (n_layers * directions, batch_size, h_dim)\n",
    "        #                       to (batch_size, n_layers * directions * h_dim)\n",
    "        hiddenLayers = torch.split(hidden, 1, 0)\n",
    "        if self.directions == 2 and self.args.n_layers == 2:\n",
    "            assert len(hiddenLayers) == 4\n",
    "        hidden_cat = torch.cat([h.squeeze(0) for h in hiddenLayers], 1)\n",
    "        mu = self.fc_mu(hidden_cat)\n",
    "        sigma_hat = self.fc_sigma(hidden_cat)\n",
    "        sigma = torch.exp(sigma_hat / 2)\n",
    "        z_size = mu.size()\n",
    "        if self.args.cuda:\n",
    "            N = Variable(torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda())\n",
    "        else:\n",
    "            N = Variable(torch.normal(torch.zeros(z_size),torch.ones(z_size)))\n",
    "        z = mu + sigma*N\n",
    "        return z, mu, sigma_hat\n",
    "\n",
    "\n",
    "\n",
    "    def init_hidden_cell(self):\n",
    "        hidden = Variable(torch.zeros(self.directions * self.args.n_layers, self.args.batch_size, self.args.encoder_h_dim))\n",
    "        cell = Variable(torch.zeros(self.directions * self.args.n_layers, self.args.batch_size, self.args.encoder_h_dim))\n",
    "        if self.args.cuda:\n",
    "            return (hidden.cuda(), cell.cuda())\n",
    "        else:\n",
    "            return (hidden, cell)\n",
    "\n",
    "class SketchRNNDecoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SketchRNNDecoder, self).__init__()\n",
    "        self.args = args\n",
    "        # to init hidden and cell from z:\n",
    "        self.fc_hc = nn.Linear(self.args.z_dim, 2 * self.args.n_layers * self.args.decoder_h_dim)\n",
    "        # unidirectional lstm:\n",
    "        self.lstm = nn.LSTM(self.args.z_dim + self.args.output_dim, self.args.decoder_h_dim, self.args.n_layers, dropout=self.args.decoder_layer_dropout)\n",
    "        self.muLayer = nn.Linear(self.args.decoder_h_dim, self.args.output_dim * self.args.n_gaussians)\n",
    "        self.sigmaLayer = nn.Linear(self.args.decoder_h_dim, self.args.output_dim * self.args.n_gaussians)\n",
    "        self.piLayer = nn.Linear(self.args.decoder_h_dim, self.args.output_dim * self.args.n_gaussians)\n",
    "\n",
    "    def forward(self, inputs, z, hidden_cell=None):\n",
    "        if hidden_cell is None:\n",
    "            layers = torch.split(torch.tanh(self.fc_hc(z)),self.args.decoder_h_dim,1)\n",
    "            hidden = torch.stack(layers[:int(len(layers) / 2)], dim=0)\n",
    "            cell = torch.stack(layers[int(len(layers) / 2): ], dim=0)\n",
    "            hidden_cell = (hidden.contiguous(), cell.contiguous())\n",
    "        outputs,(hidden,cell) = self.lstm(inputs, hidden_cell)\n",
    "        # outputs size: (seq_len, batch, num_directions * hidden_size)\n",
    "        # hidden size: (num_layers * num_directions, batch, hidden_size)\n",
    "        # cell size: (num_layers * num_directions, batch, hidden_size)\n",
    "        mu = self.muLayer(outputs).view(-1, self.args.batch_size, self.args.output_dim, self.args.n_gaussians)\n",
    "        sigma = self.sigmaLayer(outputs).view(-1, self.args.batch_size, self.args.output_dim, self.args.n_gaussians)\n",
    "        pi = self.piLayer(outputs).view(-1, self.args.batch_size, self.args.output_dim, self.args.n_gaussians)\n",
    "        pi = F.softmax(pi, 3)\n",
    "        sigma = torch.exp(sigma)\n",
    "        return (pi, mu, sigma), (hidden, cell)\n",
    "\n",
    "class SketchRNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SketchRNN, self).__init__()\n",
    "        self.args = args\n",
    "        if self.args.cuda:\n",
    "            self.encoder = SketchRNNEncoder(args).cuda()\n",
    "            self.decoder = SketchRNNDecoder(args).cuda()\n",
    "        else:\n",
    "            self.encoder = SketchRNNEncoder(args)\n",
    "            self.decoder = SketchRNNDecoder(args)\n",
    "\n",
    "    def scheduleSample(self, epoch):\n",
    "        eps = max(self.args.scheduling_start - \n",
    "            (self.args.scheduling_start - self.args.scheduling_end)* epoch / self.args.self.args.n_epochs,\n",
    "            self.args.scheduling_end)\n",
    "        return np.random.binomial(1, eps)\n",
    "\n",
    "    def generatePred(self, pi, mu, sigma):\n",
    "        if self.args.cuda:\n",
    "            N = torch.randn(pi.size()).cuda()\n",
    "            #N = torch.normal(torch.zeros(pi.size()),torch.ones(pi.size()))\n",
    "        else:\n",
    "            N = torch.randn(pi.size())\n",
    "            #N = torch.normal(torch.zeros(pi.size()),torch.ones(pi.size()))\n",
    "        clusterPredictions = mu + sigma * N\n",
    "        weightedClusterPredictions = clusterPredictions * pi\n",
    "        pred = torch.sum(weightedClusterPredictions, dim=3)\n",
    "        return pred\n",
    "\n",
    "    def allSteps(self, target, z):\n",
    "        sos = self.getStartOfSequence()\n",
    "        batch_init = torch.cat([sos, target[:-1,...]], 0)\n",
    "        z_stack = torch.stack([z]*(self.args.target_sequence_len))\n",
    "        inp = torch.cat([batch_init, z_stack], 2)\n",
    "        (pi, mu, sigma), (hidden, cell) = self.decoder(inp, z)\n",
    "        return (pi, mu, sigma)\n",
    "\n",
    "    def oneStepAtATime(self, z):\n",
    "        sos = self.getStartOfSequence()\n",
    "        inp = torch.cat([sos, z.unsqueeze(0)], 2)\n",
    "        piList, muList, sigmaList = [], [], []\n",
    "        for timeStep in range(self.args.target_sequence_len):\n",
    "            (pi, mu, sigma), (hidden, cell) = self.decoder(inp, z)\n",
    "            pred = self.generatePred(pi, mu, sigma)\n",
    "            inp = torch.cat([pred, z.unsqueeze(0)], 2)\n",
    "            piList.append(pi.detach())\n",
    "            muList.append(mu.detach())\n",
    "            sigmaList.append(sigma.detach())\n",
    "        Pi = torch.cat(piList, 0)\n",
    "        Mu = torch.cat(muList, 0)\n",
    "        Sigma = torch.cat(sigmaList, 0)\n",
    "        return (Pi, Mu, Sigma)\n",
    "\n",
    "    def getStartOfSequence(self):\n",
    "        if self.args.cuda:\n",
    "            return Variable(torch.zeros(1, self.args.batch_size, self.args.output_dim).cuda())\n",
    "        else:\n",
    "            return Variable(torch.zeros(1, self.args.batch_size, self.args.output_dim))\n",
    "\n",
    "    def doEncoding(self,batch):\n",
    "        # convert input from [input_sequence_len, batch_size, channels, x_dim]\n",
    "        #                 to [input_sequence_len, batch_size, channels * x_dim]\n",
    "        embedded = batch.contiguous().view(-1, self.args.batch_size, self.args.x_dim * self.args.channels)\n",
    "        z, mu, sigma_hat = self.encoder(embedded)\n",
    "        return z, mu, sigma_hat\n",
    "\n",
    "    def forward(self, batch, target, epoch):\n",
    "        z, latentMean, latentStd = self.doEncoding(batch)\n",
    "        if self.training:\n",
    "            (Pi, Mu, Sigma) = self.allSteps(target, z)\n",
    "        else:\n",
    "            (Pi, Mu, Sigma) = self.oneStepAtATime(z)\n",
    "        return Pi, Mu, Sigma, latentMean, latentStd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class Bunch(object):\n",
    "    def __init__(self, adict):\n",
    "        self.__dict__.update(adict)\n",
    "    def __str__(self):\n",
    "        out = \"\"\n",
    "        for k, v in self.__dict__.items():\n",
    "            out += \"{}: {}, \".format(k, v)\n",
    "        return out\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcess(object):\n",
    "    def __init__(self, modelPath,args, chooseModel=\"rnn\", dataDict=None):\n",
    "        self.args = args\n",
    "        self.modelPath = modelPath\n",
    "        if dataDict:\n",
    "            self.dataDict = dataDict\n",
    "        else:\n",
    "            self.dataDict = GetDataLoader(\"../data/traffic/trafficWithTime/\")\n",
    "        if chooseModel==\"rnn\":\n",
    "            self.model = Seq2Seq(self.args)\n",
    "        elif chooseModel==\"sketch-rnn\":\n",
    "            self.model = SketchRNN(self.args)\n",
    "        self.model.eval()\n",
    "\n",
    "    def getReconLoss(self, output, target):\n",
    "        output = self.dataDict[\"scaler\"].inverse_transform(output)\n",
    "        target = self.dataDict[\"scaler\"].inverse_transform(target)\n",
    "        assert output.size() == target.size(), \"output size: {}, target size: {}\".format(output.size(), target.size())\n",
    "        outputs = {}\n",
    "        \n",
    "        if args.criterion == \"RMSE\":\n",
    "            mse = nn.MSELoss()\n",
    "            loss = torch.sqrt(mse(output, target)).item()\n",
    "        elif args.criterion == \"L1Loss\":\n",
    "            l1loss = nn.L1Loss()\n",
    "            loss = l1loss(output, target).item()\n",
    "        return loss, output, target\n",
    "\n",
    "    def sketchRNNKLD(self, latentMean, latentStd, trainingMode, epoch):\n",
    "        LKL = -0.5*torch.sum(1+latentStd-latentMean**2-torch.exp(latentStd))\\\n",
    "                /float(args.z_dim*args.batch_size)\n",
    "        if trainingMode:\n",
    "            # update eta for LKL:\n",
    "            eta_step = 1-(1-args.eta_min)*args.R**epoch\n",
    "            if args.cuda:\n",
    "                KL_min = torch.Tensor([args.KL_min]).cuda()\n",
    "            else:\n",
    "                KL_min = torch.Tensor([args.KL_min])\n",
    "            return eta_step * torch.max(LKL, KL_min)\n",
    "        else:\n",
    "            return LKL\n",
    "\n",
    "    def getLoss(self, output, target, epoch):\n",
    "        if args.model == \"rnn\":\n",
    "            reconLoss, pred, target = self.getReconLoss(output, target)\n",
    "            kldLoss = 0\n",
    "            addtlDict = {}\n",
    "        else:\n",
    "            Pi, Mu, Sigma, latentMean, latentStd = output\n",
    "            reconLoss = self.sketchRNNReconLoss(target, Pi, Mu, Sigma)\n",
    "            kldLoss = self.sketchRNNKLD(latentMean, latentStd, self.model.training, epoch)\n",
    "            pred = self.dataDict[\"scaler\"].inverse_transform(self.model.generatePred(Pi, Mu, Sigma))\n",
    "            target = self.dataDict[\"scaler\"].inverse_transform(target)\n",
    "            addtlDict = {\n",
    "                \"Pi\" : Pi,\n",
    "                \"Mu\" : Mu,\n",
    "                \"Sigma\": Sigma,\n",
    "                \"latentMean\" : latentMean,\n",
    "                \"latentStd\" : latentStd\n",
    "            }\n",
    "        outputDict = {\n",
    "            \"reconLoss\" : reconLoss,\n",
    "            \"kldLoss\" : kldLoss,\n",
    "            \"pred\" : pred,\n",
    "            \"target\" : target,\n",
    "            \"additional\" : addtlDict\n",
    "        }\n",
    "        return outputDict\n",
    "\n",
    "    def sketchRNNReconLoss(self, target, Pi, Mu, Sigma):\n",
    "        stackedTarget = torch.stack([target] * Mu.size(3), dim=3)\n",
    "        m = torch.distributions.Normal(loc=Mu, scale=Sigma)\n",
    "        loss = torch.exp(m.log_prob(stackedTarget))\n",
    "        loss = torch.sum(loss * Pi, dim=3)\n",
    "        loss= -torch.log(loss)\n",
    "        return loss.mean()\n",
    "\n",
    "    def getEpochLoss(self, dataset, epoch):\n",
    "        datas = []\n",
    "        preds = []\n",
    "        targets = []\n",
    "        Pi = []\n",
    "        Mu = []\n",
    "        Sigma = []\n",
    "        epoch_recon_val_loss = 0.0\n",
    "        epoch_kld_val_loss = 0.0\n",
    "        nValBatches = 0\n",
    "        with torch.no_grad():\n",
    "            for batchIDX, (inputData, target) in enumerate(map(self.dataDict[\"scaler\"].transformBatchForEpoch, self.dataDict[dataset])):\n",
    "                nValBatches += 1\n",
    "                output = self.model(inputData, target, epoch)\n",
    "                lossOutputs = self.getLoss(output, target, epoch)\n",
    "                epoch_recon_val_loss += lossOutputs[\"reconLoss\"]\n",
    "                epoch_kld_val_loss += lossOutputs[\"kldLoss\"]\n",
    "                preds.append(lossOutputs[\"pred\"].cpu().detach().numpy())\n",
    "                targets.append(lossOutputs[\"target\"].cpu().detach().numpy())\n",
    "                datas.append(self.dataDict[\"scaler\"].inverse_transform(inputData[:,:,0,:]).cpu().detach().numpy())\n",
    "                if args.model == \"sketch-rnn\":\n",
    "                    Pi.append(lossOutputs[\"additional\"][\"Pi\"])\n",
    "                    Mu.append(lossOutputs[\"additional\"][\"Mu\"])\n",
    "                    Sigma.append(lossOutputs[\"additional\"][\"Sigma\"])\n",
    "                \n",
    "        datas = np.concatenate(datas, axis=0)\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        targets = np.concatenate(targets, axis=0)\n",
    "        if args.model == \"sketch-rnn\":\n",
    "            Pi = np.concatenate(Pi, axis=1)\n",
    "            Mu = np.concatenate(Mu, axis=1)\n",
    "            Sigma = np.concatenate(Sigma, axis=1)\n",
    "        retVals = {\n",
    "            \"reconLoss\" : epoch_recon_val_loss / nValBatches,\n",
    "            \"kldLoss\" : epoch_kld_val_loss / nValBatches,\n",
    "            \"preds\" : preds,\n",
    "            \"targets\" : targets,\n",
    "            \"datas\" : datas,\n",
    "            \"Pi\" : Pi,\n",
    "            \"Mu\" : Mu,\n",
    "            \"Sigma\" : Sigma\n",
    "        }\n",
    "        return retVals\n",
    "\n",
    "    def prep(self, stateDictFile, dataset, epoch):\n",
    "        desired_state_dict = torch.load(self.modelPath +stateDictFile, map_location=lambda storage, loc: storage)\n",
    "        self.model.load_state_dict(desired_state_dict)\n",
    "        self.model.eval()\n",
    "        assert dataset in [\"train\", \"val\", \"test\"]\n",
    "        \n",
    "\n",
    "    def getLossAtEpoch(self, stateDictFile, dataset, epoch= -1):\n",
    "        self.prep(stateDictFile, dataset, epoch)\n",
    "        retVals = self.getEpochLoss(dataset, epoch)\n",
    "        return retVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainValCurve(trainLosses, valLosses, trainKLDLosses=None, valKLDLosses=None):\n",
    "    plot_every = 1\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    plt.figure()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(args.criterion, color=\"r\")\n",
    "    ax1.tick_params('y', colors='r')\n",
    "    ax1.plot(np.arange(1, len(trainLosses)+1)*plot_every, trainLosses, \"r--\", label=\"train reconstruction loss\")\n",
    "    ax1.plot(np.arange(1, len(valLosses)+1)*plot_every, valLosses, color=\"red\", label=\"validation reconstruction loss\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.grid()\n",
    "    if trainKLDLosses:\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set_ylabel(\"KLD Loss\", color=\"b\")\n",
    "        ax2.tick_params('y', colors='b')\n",
    "        ax2.plot(np.arange(1, len(trainKLDLosses)+1)*plot_every, trainKLDLosses, \"b--\", label=\"train KLD loss\")\n",
    "        ax2.plot(np.arange(1, len(valKLDLosses)+1)*plot_every, valKLDLosses, color=\"blue\", label=\"val KLD loss\")\n",
    "        ax2.legend(loc=\"upper right\")\n",
    "        ax2.grid()\n",
    "    plt.title(\"Losses for {}\".format(args.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNHours(means, stds, targets, datas, dataset, dataMean, dataStd, targetTimes, N=24):\n",
    "    assert False, \"Need to fix\"\n",
    "    instance = np.random.randint(targets.shape[1])\n",
    "    sensor = np.random.randint(targets.shape[2])\n",
    "    sequenceTrueMean = []\n",
    "    sequenceTrueStd = []\n",
    "    sequenceSampleMean = []\n",
    "    sequenceSampleStd = []\n",
    "    sequenceTarget = []\n",
    "    sequenceTimes = []\n",
    "    shouldMask = []\n",
    "    maskindex = []\n",
    "    lastTime = None\n",
    "    for tStep in range(N):\n",
    "        realIndex = instance + 12 * tStep\n",
    "        if realIndex >= means.shape[1]:\n",
    "            break\n",
    "        if lastTime and inMinutes(targetTimes[realIndex, -1] - lastTime) > 5:\n",
    "            shouldMask += [True]\n",
    "        else:\n",
    "            shouldMask += [False]\n",
    "        lastTime = targetTimes[realIndex, -1]\n",
    "        maskindex += [len(sequenceTrueMean)]\n",
    "        m = means[:, realIndex, sensor]\n",
    "        std = stds[:, realIndex, sensor]\n",
    "        predSamples, sampleMean, sampleStd = getScaledSamples(m, std, dataMean, dataStd)\n",
    "        sequenceTrueMean += list(m)\n",
    "        sequenceTrueStd += list(std)\n",
    "        sequenceSampleMean += list(sampleMean)\n",
    "        sequenceSampleStd += list(sampleStd)\n",
    "        sequenceTarget += list(targets[:, realIndex, sensor])\n",
    "        sequenceTimes += list(targetTimes[realIndex])\n",
    "        \n",
    "    #f, ax = plt.subplots(2, sharex=True)\n",
    "    #f.subplots_adjust(hspace=.5)\n",
    "    \"\"\"\n",
    "    maskedSampleMean = ma.array(sequenceSampleMean)\n",
    "    maskedTarget = ma.array(sequenceTarget)\n",
    "    print(maskindex)\n",
    "    print(shouldMask)\n",
    "    print(maskedSampleMean.shape)\n",
    "    for idx, should in zip(maskindex, shouldMask):\n",
    "        if should:\n",
    "            maskedSampleMean[idx] = ma.masked\n",
    "            maskedTarget[idx] = ma.masked\n",
    "    \"\"\"\n",
    "    #print(np.max(sequenceSampleStd), sequenceTimes[np.argmax(sequenceSampleStd)])\n",
    "    #print(sequenceSampleMean)\n",
    "    f, ax = plt.subplots()\n",
    "    f.set_figwidth(15)\n",
    "    plt.plot(sequenceTimes, sequenceSampleMean, label=\"pred\")\n",
    "    plt.plot(sequenceTimes, sequenceTarget, label=\"target\")\n",
    "    plt.fill_between(sequenceTimes,np.array(sequenceSampleMean)-1.96*np.array(sequenceSampleStd), np.array(sequenceSampleMean)+1.96*np.array(sequenceSampleStd), alpha=0.5)\n",
    "    plt.xticks(rotation=90)\n",
    "    xfmt = md.DateFormatter('%Y-%m-%d %H:%M:%S')\n",
    "    ax=plt.gca()\n",
    "    ax.xaxis.set_major_formatter(xfmt)\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"mile/h\")\n",
    "    plt.title(\"{} Hour Sample Prediction {}\".format(N, dataset))\n",
    "    yMin = np.min((np.min(sequenceSampleMean)-10, np.min(sequenceTarget)-10, 10))\n",
    "    yMax = np.max((np.max(sequenceSampleMean)+10, np.max(sequenceTarget)+10, 70))\n",
    "    #plt.ylim((yMin,yMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
