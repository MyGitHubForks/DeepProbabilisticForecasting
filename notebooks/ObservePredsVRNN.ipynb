{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = \"./save/server2Models/vrnn/vrnn25/\"\n",
    "meansVT = torch.load(baseDir+\"validation_means\", map_location=\"cpu\")\n",
    "stdsVT = torch.load(baseDir+\"validation_stds\", map_location=\"cpu\")\n",
    "targetsVT = torch.load(baseDir+\"validation_targets\", map_location=\"cpu\")\n",
    "inputsVT = torch.load(baseDir+\"validation_datas\", map_location=\"cpu\")\n",
    "meansTT = torch.load(baseDir+\"train_means\", map_location=\"cpu\")\n",
    "stdsTT = torch.load(baseDir+\"train_stds\", map_location=\"cpu\")\n",
    "targetsTT = torch.load(baseDir+\"train_targets\", map_location=\"cpu\")\n",
    "inputsTT = torch.load(baseDir+\"train_datas\", map_location=\"cpu\")\n",
    "trainDataMean = torch.load(baseDir+\"train_mean\", map_location=\"cpu\")\n",
    "trainDataStd = torch.load(baseDir+\"train_std\", map_location=\"cpu\")\n",
    "valDataMean = torch.load(baseDir+\"val_mean\", map_location=\"cpu\")\n",
    "valDataStd = torch.load(baseDir+\"val_std\", map_location=\"cpu\")\n",
    "avgTrainKLDLosses = torch.load(baseDir+\"mean_train_kld_losses_per_timestep\", map_location=\"cpu\")\n",
    "avgValKLDLosses = torch.load(baseDir+\"mean_validation_kld_losses_per_timestep\", map_location=\"cpu\")\n",
    "plotTrainKLDLosses = torch.load(baseDir+\"plot_train_kld_losses\", map_location=\"cpu\")\n",
    "plotValKLDLosses = torch.load(baseDir+\"plot_val_kld_losses\", map_location=\"cpu\")\n",
    "plotTrainReconLosses = torch.load(baseDir+\"plot_train_recon_losses\", map_location=\"cpu\")\n",
    "plotValReconLosses = torch.load(baseDir+\"plot_val_recon_losses\", map_location=\"cpu\")\n",
    "learningRates = torch.load(baseDir+\"learningRates\", map_location=\"cpu\")\n",
    "dataTimesArrTrain = np.array(torch.load(baseDir+\"dataTimesArrTrain\", map_location=\"cpu\"))\n",
    "dataTimesArrTrain = np.reshape(dataTimesArrTrain, (-1, dataTimesArrTrain.shape[-1]))\n",
    "targetTimesArrTrain = np.array(torch.load(baseDir+\"targetTimesArrTrain\", map_location=\"cpu\"))\n",
    "targetTimesArrTrain = np.reshape(targetTimesArrTrain, (-1, targetTimesArrTrain.shape[-1]))\n",
    "dataTimesArrVal = np.array(torch.load(baseDir+\"dataTimesArrVal\", map_location=\"cpu\"))\n",
    "dataTimesArrVal = np.reshape(dataTimesArrVal, (-1, dataTimesArrVal.shape[-1]))\n",
    "targetTimesArrVal = np.array(torch.load(baseDir+\"targetTimesArrVal\", map_location=\"cpu\"))\n",
    "targetTimesArrVal = np.reshape(targetTimesArrVal, (-1, targetTimesArrVal.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 10, 207)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meansTT[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTimeOrder = dataTimesArrTrain[:,0].argsort()\n",
    "valTimeOrder = dataTimesArrVal[:,0].argsort()\n",
    "dataTimesArrTrain = dataTimesArrTrain[trainTimeOrder]\n",
    "targetTimesArrTrain = targetTimesArrTrain[trainTimeOrder]\n",
    "dataTimesArrVal = dataTimesArrVal[valTimeOrder]\n",
    "targetTimesArrVal = targetTimesArrVal[valTimeOrder]\n",
    "meansT = np.concatenate([p for p in meansTT], axis=1)[:,trainTimeOrder,:]\n",
    "stdsT = np.concatenate([p for p in stdsTT], axis=1)[:,trainTimeOrder,:]\n",
    "targetsT = np.concatenate([t for t in targetsTT], axis=1)[:,trainTimeOrder,:]\n",
    "datasT = np.concatenate([d for d in inputsTT], axis=1)[:,trainTimeOrder,:]\n",
    "meansV = np.concatenate([p for p in meansVT], axis=1)[:,valTimeOrder,:]\n",
    "stdsV = np.concatenate([p for p in stdsVT], axis=1)[:,valTimeOrder,:]\n",
    "targetsV = np.concatenate([t for t in targetsVT], axis=1)[:,valTimeOrder,:]\n",
    "datasV = np.concatenate([d for d in inputsVT], axis=1)[:,valTimeOrder,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 23970, 207)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meansT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2397, (12, 10, 207))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meansTT), meansTT[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScaledSamples(generatorMean, generatorStd, dataMean, dataStd):\n",
    "    standardizedSamples = np.random.normal(generatorMean, generatorStd, size=(100, generatorMean.shape[0]))\n",
    "    samples = (standardizedSamples * dataStd) + dataMean\n",
    "    meanofsamples = np.mean(samples, axis=0)\n",
    "    stdofsamples = np.std(samples, axis=0)\n",
    "    return samples, meanofsamples, stdofsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inMinutes(td):\n",
    "    return (td.seconds//60)%60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNHours(means, stds, targets, datas, dataset, dataMean, dataStd, targetTimes, N=24):\n",
    "    instance = np.random.randint(targets.shape[1])\n",
    "    sensor = np.random.randint(targets.shape[2])\n",
    "    sequenceTrueMean = []\n",
    "    sequenceTrueStd = []\n",
    "    sequenceSampleMean = []\n",
    "    sequenceSampleStd = []\n",
    "    sequenceTarget = []\n",
    "    sequenceTimes = []\n",
    "    shouldMask = []\n",
    "    maskindex = []\n",
    "    lastTime = None\n",
    "    for tStep in range(N):\n",
    "        realIndex = instance + 12 * tStep\n",
    "        if realIndex >= means.shape[1]:\n",
    "            break\n",
    "        if lastTime and inMinutes(targetTimes[realIndex, -1] - lastTime) > 5:\n",
    "            shouldMask += [True]\n",
    "        else:\n",
    "            shouldMask += [False]\n",
    "        lastTime = targetTimes[realIndex, -1]\n",
    "        maskindex += [len(sequenceTrueMean)]\n",
    "        m = means[:, realIndex, sensor]\n",
    "        std = stds[:, realIndex, sensor]\n",
    "        predSamples, sampleMean, sampleStd = getScaledSamples(m, std, dataMean, dataStd)\n",
    "        sequenceTrueMean += list(m)\n",
    "        sequenceTrueStd += list(std)\n",
    "        sequenceSampleMean += list(sampleMean)\n",
    "        sequenceSampleStd += list(sampleStd)\n",
    "        sequenceTarget += list(targets[:, realIndex, sensor])\n",
    "        sequenceTimes += list(targetTimes[realIndex])\n",
    "        \n",
    "    #f, ax = plt.subplots(2, sharex=True)\n",
    "    #f.subplots_adjust(hspace=.5)\n",
    "    \"\"\"\n",
    "    maskedSampleMean = ma.array(sequenceSampleMean)\n",
    "    maskedTarget = ma.array(sequenceTarget)\n",
    "    print(maskindex)\n",
    "    print(shouldMask)\n",
    "    print(maskedSampleMean.shape)\n",
    "    for idx, should in zip(maskindex, shouldMask):\n",
    "        if should:\n",
    "            maskedSampleMean[idx] = ma.masked\n",
    "            maskedTarget[idx] = ma.masked\n",
    "    \"\"\"\n",
    "    #print(np.max(sequenceSampleStd), sequenceTimes[np.argmax(sequenceSampleStd)])\n",
    "    #print(sequenceSampleMean)\n",
    "    f, ax = plt.subplots()\n",
    "    f.set_figwidth(15)\n",
    "    plt.plot(sequenceTimes, sequenceSampleMean, label=\"pred\")\n",
    "    plt.plot(sequenceTimes, sequenceTarget, label=\"target\")\n",
    "    plt.fill_between(sequenceTimes,np.array(sequenceSampleMean)-1.96*np.array(sequenceSampleStd), np.array(sequenceSampleMean)+1.96*np.array(sequenceSampleStd), alpha=0.5)\n",
    "    plt.xticks(rotation=90)\n",
    "    xfmt = md.DateFormatter('%Y-%m-%d %H:%M:%S')\n",
    "    ax=plt.gca()\n",
    "    ax.xaxis.set_major_formatter(xfmt)\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"mile/h\")\n",
    "    plt.title(\"{} Hour Sample Prediction {}\".format(N, dataset))\n",
    "    yMin = np.min((np.min(sequenceSampleMean)-10, np.min(sequenceTarget)-10, 10))\n",
    "    yMax = np.max((np.max(sequenceSampleMean)+10, np.max(sequenceTarget)+10, 70))\n",
    "    #plt.ylim((yMin,yMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotNHours(meansT, stdsT, targetsT, datasT, \"Train\", trainDataMean, trainDataStd, targetTimesArrTrain, N=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotNHours(meansV, stdsV, targetsV, datasV, \"Validation\", valDataMean, valDataStd, targetTimesArrVal, N=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRandomInstanceVRNN(means, stds, targets, datas, dataset, dataMean, dataStd):\n",
    "    instance = np.random.randint(targets.shape[1])\n",
    "    sensor = np.random.randint(targets.shape[2])\n",
    "    m = means[:, instance, sensor]\n",
    "    std = stds[:, instance, sensor]\n",
    "    print(m)\n",
    "    print(std)\n",
    "    t = targets[:, instance, sensor]\n",
    "    d = datas[:,instance, sensor]\n",
    "    predSamples, samplesMean, samplesStd = getScaledSamples(m, std, dataMean, dataStd)\n",
    "    f, ax = plt.subplots(2, sharex=True)\n",
    "    f.subplots_adjust(hspace=.5)\n",
    "    ax[0].plot(range(0,60, 5),samplesMean, label=\"pred\")\n",
    "    ax[0].fill_between(range(0,60, 5),samplesMean-1.96*samplesStd, samplesMean+1.96*samplesStd, alpha=0.5)\n",
    "    ax[0].plot(range(0,60, 5),t, label=\"target\")\n",
    "    ax[0].plot(range(-60,0, 5), d, label=\"input\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel(\"Minutes relative to prediction time\")\n",
    "    ax[0].set_ylabel(\"Speed (mph)\")\n",
    "    ax[0].set_title(\"random sensor sample {}\".format(dataset))\n",
    "    ax[1].plot(range(0,60, 5), m, label=\"mean\")\n",
    "    ax[1].fill_between(range(0,60, 5),m-1.96*std, m+1.96*std, alpha=0.5)\n",
    "    ax[1].set_title(\"True mean and 95% C.I.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotRandomInstanceVRNN(meansT,stdsT, targetsT, datasT, \"Train\", trainDataMean, trainDataStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotRandomInstanceVRNN(meansV, stdsV, targetsV, datasV, \"Validation\", valDataMean, valDataStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avgTrainKLDLosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avgValKLDLosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainValCurve(trainLosses, valLosses, trainKLDLosses=None, valKLDLosses=None):\n",
    "    plot_every = 1\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    plt.figure()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"loss\", color=\"r\")\n",
    "    ax1.tick_params('y', colors='r')\n",
    "    ax1.plot(np.arange(1, len(trainLosses)+1)*plot_every, trainLosses, \"r--\", label=\"train reconstruction loss\")\n",
    "    ax1.plot(np.arange(1, len(valLosses)+1)*plot_every, valLosses, color=\"red\", label=\"validation reconstruction loss\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.grid()\n",
    "    if trainKLDLosses:\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set_ylabel(\"KLD Loss\", color=\"b\")\n",
    "        ax2.tick_params('y', colors='b')\n",
    "        ax2.plot(np.arange(1, len(trainKLDLosses)+1)*plot_every, trainKLDLosses, \"b--\", label=\"train KLD loss\")\n",
    "        ax2.plot(np.arange(1, len(valKLDLosses)+1)*plot_every, valKLDLosses, color=\"blue\", label=\"val KLD loss\")\n",
    "        ax2.legend(loc=\"upper right\")\n",
    "        ax2.grid()\n",
    "    plt.title(\"Losses for VRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrainValCurve(plotTrainReconLosses, plotValReconLosses, plotTrainKLDLosses, plotValKLDLosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sqrt(np.mean(((trainDataMean + trainDataStd* meansT) - targetsT)**2, axis=(1,2))))\n",
    "ticks = plt.xticks(np.arange(0,12))\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.title(\"Average loss by timestep, Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sqrt(np.mean(((valDataMean + valDataStd* meansV) - targetsV)**2, axis=(1,2))))\n",
    "ticks = plt.xticks(np.arange(0,12))\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.title(\"Average loss by timestep, Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(((valDataMean + valDataStd* meansV) - targetsV)**2, axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
