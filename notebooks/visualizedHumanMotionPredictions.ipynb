{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run GetLossObj.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = \"../save/server1/rnn/model130/\"\n",
    "plotTrainReconLosses = torch.load(baseDir + \"plot_train_recon_losses\", map_location=\"cpu\")\n",
    "plotValReconLosses = torch.load(baseDir + \"plot_val_recon_losses\", map_location=\"cpu\")\n",
    "with open(baseDir + \"args.txt\") as f:\n",
    "    args = f.read()\n",
    "args = Bunch(json.loads(args))\n",
    "args.no_cuda = True\n",
    "args.cuda = False\n",
    "args.dropout= 0.0\n",
    "if args.dataset == \"traffic\":\n",
    "    args.output_dim = args.x_dim\n",
    "else: #args.dataset == \"human\":\n",
    "    args.output_dim = args.x_dim * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.dataset, args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/Users/danielzeiberg/Documents/Data/Human/Processed/INPUT_HORIZON_25_PREDICTION_HORIZON_50/\"\n",
    "dataDict = getDataLoaders(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show2D(img, predPoints, targetPoints):\n",
    "    ref = {\"nJoints\" : 16,\n",
    "           \"accIdxs\" : [0, 1, 2, 3, 4, 5, 10, 11, 14, 15],\n",
    "           \"shuffleRef\" : [[0, 5], [1, 4], [2, 3], \n",
    "                 [10, 15], [11, 14], [12, 13]],\n",
    "           \"edges\" : [[0, 1], [1, 2], [2, 6], [6, 3], [3, 4], [4, 5], \n",
    "             [10, 11], [11, 12], [12, 8], [8, 13], [13, 14], [14, 15], \n",
    "             [6, 8], [8, 9]]\n",
    "          }\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.33\n",
    "    fontColor = (255,255,255)\n",
    "    lineType = 2\n",
    "    for points, c, of in zip([predPoints, targetPoints], [(255,0,0), (0,0,255)], [0,100]):\n",
    "        points = ((points.reshape(ref[\"nJoints\"], -1))).astype(np.int32)\n",
    "        for e in ref[\"edges\"]:\n",
    "            cv2.line(img, (points[e[0], 0]+of, points[e[0], 1]), (points[e[1], 0]+of, points[e[1], 1]), (0,0,0), 2)\n",
    "        for j in range(ref[\"nJoints\"]):\n",
    "            #cv2.putText(img, str(j), (points[j, 0], points[j, 1]), font, fontScale, fontColor, lineType)\n",
    "            cv2.circle(img, (points[j, 0]+of, points[j, 1]), 5, c, -1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getlossobj = PostProcess(baseDir,args, dataDict=dataDict, chooseModel=\"rnn\")\n",
    "getlossobj.prep(\"rnn_full_model.pth\", \"train\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(os.path.join(dataDir, \"train.h5\"), \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTimes = np.arange(1, 25 * 5 + 1, 5)\n",
    "targetTimes = np.arange(1 + 25*5, 1 + 75*5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTargets = []\n",
    "allOutputs = []\n",
    "allInputs = []\n",
    "loss = nn.L1Loss()\n",
    "for batchStop in range(64, 64 * 100, 64):\n",
    "    print(batchStop-64, batchStop)\n",
    "    inputT = torch.Tensor(f[\"input2d\"][batchStop - 64:batchStop])\n",
    "    allInputs.append(inputT)\n",
    "    targetT = torch.Tensor(f[\"target2d\"][batchStop - 64:batchStop])\n",
    "    transInput, transTarget = dataDict[\"scaler\"].transformBatchForEpoch((inputT, targetT))\n",
    "    output = getlossobj.model(transInput, transTarget, 0)\n",
    "    reconFirstOutput = dataDict[\"scaler\"].inverse_transform(output)\n",
    "    reconFirstTarget = dataDict[\"scaler\"].inverse_transform(transTarget)\n",
    "    print(loss(reconFirstOutput, reconFirstTarget))\n",
    "    allOutputs.append(reconFirstOutput.cpu().detach().numpy())\n",
    "    allTargets.append(reconFirstTarget.cpu().detach().numpy())\n",
    "allOutputs = np.concatenate(allOutputs, axis=0)\n",
    "allInputs = np.concatenate(allInputs, axis=0)\n",
    "allTargets = np.concatenate(allTargets, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allInputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allOutputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTargets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = np.concatenate((np.transpose(allInputs, (0,1,3,2)), allOutputs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTimes = np.concatenate((inputTimes, targetTimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convNum(num):\n",
    "    if num < 10:\n",
    "        return \"0\"+str(num)\n",
    "    else:\n",
    "        return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convNum(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allInputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    inst = np.random.choice(allOutputs.shape[0])\n",
    "    whiteImage = cv2.imread(\"/Users/danielzeiberg/Downloads/white.png\")\n",
    "\n",
    "    def getImg(timeStepIdx):\n",
    "        imgString = \"/Users/danielzeiberg/Documents/Data/Human/images/\"\n",
    "        imgString += \"s_{}_act_{}_subact_{}_ca_{}/s_{}_act_{}_subact_{}_ca_{}_{}{}.jpg\".format(\n",
    "                            convNum(f[\"subject\"][inst]), convNum(f[\"action\"][inst]), convNum(f[\"subaction\"][inst]), convNum(f[\"camera\"][inst]),\\\n",
    "                            convNum(f[\"subject\"][inst]), convNum(f[\"action\"][inst]), convNum(f[\"subaction\"][inst]), convNum(f[\"camera\"][inst]),\\\n",
    "                            \"0\" *( 6 - len(str(allTimes[timeStepIdx]))), allTimes[timeStepIdx])\n",
    "        criterion = nn.L1Loss()\n",
    "        whiteImage = cv2.imread(\"/Users/danielzeiberg/Downloads/white.png\")\n",
    "        return show2D(whiteImage, allOutputs[inst,timeStepIdx].T, allTargets[inst,timeStepIdx].T)\n",
    "\n",
    "    def getBase(timeStepIdx):\n",
    "        imgString = \"/Users/danielzeiberg/Documents/Data/Human/images/\"\n",
    "        imgString += \"s_{}_act_{}_subact_{}_ca_{}/s_{}_act_{}_subact_{}_ca_{}_{}{}.jpg\".format(\n",
    "                            convNum(f[\"subject\"][inst]), convNum(f[\"action\"][inst]), convNum(f[\"subaction\"][inst]), convNum(f[\"camera\"][inst]),\\\n",
    "                            convNum(f[\"subject\"][inst]), convNum(f[\"action\"][inst]), convNum(f[\"subaction\"][inst]), convNum(f[\"camera\"][inst]),\\\n",
    "                            \"0\" *( 6 - len(str(allTimes[timeStepIdx]))), allTimes[timeStepIdx])\n",
    "\n",
    "        criterion = nn.L1Loss()\n",
    "        whiteImage = cv2.imread(\"/Users/danielzeiberg/Downloads/white.png\")\n",
    "        return show2D(whiteImage, allInputs[inst,timeStepIdx], allInputs[inst,timeStepIdx])\n",
    "    # images = [getBase(i) for i in range(25)] +[whiteImage]+ [getImg(i) for i in range(50)]\n",
    "    images = [getImg(i) for i in range(50)]\n",
    "    predNum= 0\n",
    "    while os.path.isfile(baseDir+\"preds_{}.gif\".format(predNum)):\n",
    "        predNum += 1\n",
    "    imageio.mimsave(baseDir+'preds_{}.gif'.format(predNum), images, fps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(f[\"subject\"][:6336]), np.unique(f[\"action\"][:6336]), np.unique(f[\"subaction\"][:6336]), np.unique(f[\"camera\"][:6336])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
