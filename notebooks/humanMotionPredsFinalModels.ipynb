{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run GetLossObj.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "# modelNumbers = [156, 161, 159, 158, 162, 160, 155, 154]\n",
    "modelNumbers = [172, 173]\n",
    "baseDir = \"../save/models/model{}/\"\n",
    "for modelNumber in modelNumbers:\n",
    "    models[modelNumber] = {}\n",
    "    dirs = baseDir.format(modelNumber)\n",
    "    with open(dirs + \"args.txt\") as f:\n",
    "        args = f.read()\n",
    "    args = Bunch(json.loads(args))\n",
    "    args.no_cuda = True\n",
    "    args.cuda = False\n",
    "    args.dropout= 0.0\n",
    "    if args.dataset == \"traffic\":\n",
    "        args.output_dim = args.x_dim\n",
    "    else: #args.dataset == \"human\":\n",
    "        args.output_dim = args.x_dim * 2\n",
    "    models[modelNumber][\"args\"] = args\n",
    "    model = RecurrentSeq2Seq(\n",
    "                args.h_dim,\n",
    "                args.dropout_prob,\n",
    "                args.rnn_type,\n",
    "                args.bidirectionalEncoder,\n",
    "                args.n_layers,\n",
    "                args.attention_type,\n",
    "                args.input_feeding,\n",
    "                args.x_dim * args.channels,\n",
    "                args.output_dim,\n",
    "                args)\n",
    "    desired_state_dict = torch.load(dirs+\"Seq2SeqAttn_full_model.pth\", map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(desired_state_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    models[modelNumber][\"model\"] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show2D(img, predPoints, targetPoints):\n",
    "    ref = {\"nJoints\" : 16,\n",
    "           \"accIdxs\" : [0, 1, 2, 3, 4, 5, 10, 11, 14, 15],\n",
    "           \"shuffleRef\" : [[0, 5], [1, 4], [2, 3], \n",
    "                 [10, 15], [11, 14], [12, 13]],\n",
    "           \"edges\" : [[0, 1], [1, 2], [2, 6], [6, 3], [3, 4], [4, 5], \n",
    "             [10, 11], [11, 12], [12, 8], [8, 13], [13, 14], [14, 15], \n",
    "             [6, 8], [8, 9]]\n",
    "          }\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.33\n",
    "    fontColor = (255,255,255)\n",
    "    lineType = 2\n",
    "    for points, c, of in zip([predPoints, targetPoints], [(255,0,0), (0,0,255)], [0,100]):\n",
    "        points = ((points.reshape(ref[\"nJoints\"], -1))).astype(np.int32)\n",
    "        for e in ref[\"edges\"]:\n",
    "            cv2.line(img, (points[e[0], 0]+of, points[e[0], 1]), (points[e[1], 0]+of, points[e[1], 1]), (0,0,0), 2)\n",
    "        for j in range(ref[\"nJoints\"]):\n",
    "            #cv2.putText(img, str(j), (points[j, 0], points[j, 1]), font, fontScale, fontColor, lineType)\n",
    "            cv2.circle(img, (points[j, 0]+of, points[j, 1]), 5, c, -1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/home/dan/data/Human/Processed/INPUT_HORIZON_25_PREDICTION_HORIZON_50/\"\n",
    "f = h5py.File(os.path.join(dataDir, \"test.h5\"), \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, scaler, _, _, _, _ = getHumanDataset(dataDir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTimes = np.arange(1, 25 * 5 + 1, 5)\n",
    "targetTimes = np.arange(1 + 25*5, 1 + 75*5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"input2d\"].shape[0] / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTargets = []\n",
    "allInputs = []\n",
    "nBatches = int(np.floor(f[\"input2d\"].shape[0] / 64))\n",
    "for model in models.values():    \n",
    "    model[\"allOutputs\"] = []\n",
    "loss = nn.L1Loss()\n",
    "for i, batchStop in enumerate(range(64, 64 * (nBatches + 1), 64)):\n",
    "    print(i + 1,\" / \",nBatches)\n",
    "    inputT = torch.Tensor(f[\"input2d\"][batchStop - 64:batchStop])\n",
    "    targetT = torch.Tensor(f[\"target2d\"][batchStop - 64:batchStop])\n",
    "    transInput, transTarget = scaler.transformBatchForEpoch((inputT, targetT))\n",
    "    allTargets.append(targetT.cpu().detach().numpy())\n",
    "    allInputs.append(inputT.cpu().detach().numpy())\n",
    "    for model in models.values():\n",
    "        output = model[\"model\"](transInput, transTarget, 0)\n",
    "        reconOutput = scaler.inverse_transform(output)\n",
    "        model[\"allOutputs\"].append(reconOutput.cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model[\"allOutputs\"] = np.concatenate(model[\"allOutputs\"], axis=0)\n",
    "allInputs = np.concatenate(allInputs, axis=0)\n",
    "allTargets = np.concatenate(allTargets, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model[\"allOutputs\"] = np.transpose(model[\"allOutputs\"], (0,1,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allInputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[modelNumbers[0]][\"allOutputs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTargets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modelNum, model in models.items():\n",
    "    losses = []\n",
    "    for stopSec in [10,20,30,40,50]:\n",
    "        losses.append(np.mean(np.abs(model[\"allOutputs\"][:,:stopSec,:,:] - allTargets[:,:stopSec,:,:])))\n",
    "    print(modelNum)\n",
    "    print(\"{:.2f} & {:.2f} & {:.2f} & {:.2f} & {:.2f}\".format(*losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    inst = np.random.choice(models[modelNumbers[0]][\"allOutputs\"].shape[0])\n",
    "    def getImg(allOutputs, timeStepIdx):\n",
    "        whiteImage = cv2.imread(\"/Users/danielzeiberg/Downloads/white.png\")\n",
    "        return show2D(whiteImage, allOutputs[inst,timeStepIdx], allTargets[inst,timeStepIdx])\n",
    "\n",
    "    for modelNum in modelNumbers:\n",
    "        modelDir = baseDir.format(modelNum)\n",
    "        predNum = 0\n",
    "        while os.path.isfile(modelDir+\"motionPred{}Test.png\".format(predNum)):\n",
    "            predNum += 1\n",
    "        images = []\n",
    "        for i in range(50):\n",
    "            whtIMG = cv2.imread(\"/home/dan/white.png\")\n",
    "            img = show2D(whtIMG, models[modelNum][\"allOutputs\"][inst, i], allTargets[inst, i])\n",
    "            images.append(img)\n",
    "        imageio.mimsave(modelDir+\"motionPred{}Test.gif\".format(predNum), images, fps=4)\n",
    "        plt.figure(figsize = (8,12))\n",
    "    #     gs1 = gridspec.GridSpec(10, 5, wspace=0, hspace=0)\n",
    "    #     plt.figure(figsize = (6,6)) # set the figure size to be square\n",
    "        gs1 = gridspec.GridSpec(10, 5)\n",
    "        # set the space between subplots and the position of the subplots in the figure\n",
    "        gs1.update(wspace=0.0, hspace=0.0, left = 0.0, right = 5.0, bottom = 0.0, top = 5.0)\n",
    "    #     gs1.update(wspace=0.0001, hspace=0.0001) # set the spacing between axes. \n",
    "        for i in range(50):\n",
    "           # i = i + 1 # grid spec indexes from 0\n",
    "            ax1 = plt.subplot(gs1[i])\n",
    "            plt.axis('on')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "            ax1.set_aspect('equal')\n",
    "    #         ax1.plot([0,1],[0,0])\n",
    "            ax1.imshow(images[i-1].astype(np.uint8))\n",
    "        plt.savefig(modelDir+\"motionPred{}Test.png\".format(predNum), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(f[\"subject\"][:6336]), np.unique(f[\"action\"][:6336]), np.unique(f[\"subaction\"][:6336]), np.unique(f[\"camera\"][:6336])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whtIMG = cv2.imread(\"/home/dan/white.png\")\n",
    "img = show2D(whtIMG, models[modelNumbers[0]][\"allOutputs\"][0,0], allTargets[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "gs1 = gridspec.GridSpec(4, 4)\n",
    "gs1.update(wspace=0.025, hspace=0.05) # set the spacing between axes. \n",
    "\n",
    "for i in range(16):\n",
    "   # i = i + 1 # grid spec indexes from 0\n",
    "    ax1 = plt.subplot(gs1[i])\n",
    "    plt.axis('off')\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_yticklabels([])\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.plot([0,1],[0,1])\n",
    "#     plt.subp\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
